{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0445192",
   "metadata": {},
   "source": [
    "# Analysis Notebook for Comparing LLMs as Annotators for Skin Tone Perception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61bc9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages \n",
    "import re\n",
    "import pandas as pd\n",
    "from pingouin import intraclass_corr\n",
    "from typing import Union, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import krippendorff  \n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.stats import chi2\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# R integration via rpy2\n",
    "try:\n",
    "    import rpy2.robjects as ro\n",
    "    from rpy2.robjects import r\n",
    "    from rpy2.robjects.packages import importr, isinstalled\n",
    "    from rpy2.robjects.vectors import StrVector\n",
    "    from rpy2.robjects import pandas2ri\n",
    "    from rpy2.robjects.conversion import localconverter\n",
    "\n",
    "    # ensure CRAN mirror + required packages\n",
    "    utils = importr('utils')\n",
    "    try:\n",
    "        utils.chooseCRANmirror(ind=1)\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    needed = [pkg for pkg in (\"lme4\", \"emmeans\") if not isinstalled(pkg)]\n",
    "    if needed:\n",
    "        utils.install_packages(StrVector(needed))\n",
    "\n",
    "    # load packages\n",
    "    lme4 = importr(\"lme4\")\n",
    "    emmeans = importr(\"emmeans\")\n",
    "\n",
    "    # simple smoke test\n",
    "    _ = r(\"R.version.string\")\n",
    "    R_AVAILABLE = True\n",
    "    print(\"R bridge ready.\")\n",
    "except Exception as e:\n",
    "    print(\"R bridge init failed:\", e)\n",
    "    R_AVAILABLE = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2e04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_path = os.path.join(os.getcwd(), 'data/annotations')\n",
    "image_path = os.path.join(os.getcwd(), 'data/images')\n",
    "output_path = os.path.join(os.getcwd(), 'outputs')\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c15803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs \n",
    "ACTIVE_MODELS_KEYS = [\"GPT\", \"Claude\", \"Llama\", \"Gemini\"]\n",
    "PROMPT_VARIATIONS_KEYS = [\"With Monk Scale\"] \n",
    "CONTEXT_CONDITIONS_KEYS = [\n",
    "    \"baseline\", \"ignore_world\", \"embrace_world\", \"cultural_white\",\n",
    "    \"cultural_black\", \"cultural_asain\", \"cultural_hispanic\",\n",
    "    \"cultural_indigenous\", \"cultural_africanamerican\", \"cultural_colorism\",\n",
    "    \"cultural_lighter\", \"cultural_darker\"\n",
    "]\n",
    "\n",
    "    # Define color mapping for model families\n",
    "model_colors = {\n",
    "        'GPT': '#2ecc71',    # Green\n",
    "        'Claude': '#e74c3c', # Red\n",
    "        'Llama': '#3498db',  # Blue\n",
    "        'Gemini': '#f1c40f', # Yellow\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9212576",
   "metadata": {},
   "source": [
    "## 1. Loading Data & Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35296a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_annotations = pd.read_csv(os.path.join(data_path, 'WITHMONKSCALE_concatenated_FINALdata.csv'))\n",
    "\n",
    "print(\"Data Shape:\", raw_annotations.shape)\n",
    "print(\"Columns:\", raw_annotations.columns.tolist())\n",
    "print(\"First few rows of data:\")\n",
    "print(raw_annotations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e283ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_annotations.copy()\n",
    "# Parse the LLM responses\n",
    "\n",
    "def parse_llm_response(text):\n",
    "    \"\"\"\n",
    "    Parse an LLM response text based on the format:\n",
    "    Monk Rating: [1–10]\n",
    "    Confidence: [1–7]\n",
    "    Rationale: [up to 40 words]\n",
    "\n",
    "    Also handles \"Monk:\" or \"Rating:\" for scale for flexibility with older analysis.py.\n",
    "    The new primary format is \"Monk Rating:\".\n",
    "    \n",
    "    Returns:\n",
    "        (scale_numeric, confidence, rationale)\n",
    "        If parsing fails, returns (None, None, None).\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return (None, None, None)\n",
    "\n",
    "    scale_numeric = None\n",
    "    confidence = None\n",
    "    rationale = None\n",
    "\n",
    "    # Try parsing the specific \"Monk Rating:\" format first\n",
    "    scale_match_specific = re.search(r'Monk Rating:\\s*(\\d+)', text, re.IGNORECASE)\n",
    "    if scale_match_specific:\n",
    "        try:\n",
    "            scale_numeric = int(scale_match_specific.group(1))\n",
    "        except ValueError:\n",
    "            scale_numeric = None\n",
    "    else:\n",
    "        # Fallback to more general patterns if specific one not found\n",
    "        # Handles \"Monk: X\" or \"Rating: X\"\n",
    "        scale_pattern_general = r'(?:Monk:\\s*(\\d+)|Rating:\\s*(\\d+))'\n",
    "        scale_match_general = re.search(scale_pattern_general, text, re.IGNORECASE)\n",
    "        if scale_match_general:\n",
    "            if scale_match_general.group(1): # Monk: X\n",
    "                try:\n",
    "                    scale_numeric = int(scale_match_general.group(1))\n",
    "                except ValueError:\n",
    "                    scale_numeric = None\n",
    "            elif scale_match_general.group(2): # Rating: X\n",
    "                try:\n",
    "                    scale_numeric = int(scale_match_general.group(2))\n",
    "                except ValueError:\n",
    "                    scale_numeric = None\n",
    "    \n",
    "    # Extract confidence (e.g., \"Confidence: 3\" or \"Confidence: (3)\")\n",
    "    conf_pattern = r'Confidence:\\s*\\(?(\\d+)\\)?'\n",
    "    conf_match = re.search(conf_pattern, text, re.IGNORECASE)\n",
    "    if conf_match:\n",
    "        try:\n",
    "            confidence = int(conf_match.group(1))\n",
    "        except ValueError:\n",
    "            confidence = None\n",
    "\n",
    "    # Extract rationale (everything after \"Rationale:\")\n",
    "    rationale_pattern = r'Rationale:\\s*(.*)'\n",
    "    rat_match = re.search(rationale_pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "    if rat_match:\n",
    "        rationale = rat_match.group(1).strip()\n",
    "\n",
    "    return (scale_numeric, confidence, rationale)\n",
    "\n",
    "def build_long_df(df: pd.DataFrame, ACTIVE_MODELS_KEYS: list, CONTEXT_CONDITIONS_KEYS: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert wide-format raw response columns into long-format DataFrame.\n",
    "    Expects 'image_name' and raw columns named MODEL_Variation_Condition.\n",
    "    Handles conditions with underscores.\n",
    "    \"\"\"\n",
    "    records = []\n",
    "    for col in df.columns:\n",
    "        if col in ('image_name', 'image_path'):\n",
    "            continue\n",
    "        parts = col.split('_', 2) \n",
    "        if len(parts) < 3:\n",
    "            continue\n",
    "        model, condition = parts[0], parts[2]\n",
    "        if model not in ACTIVE_MODELS_KEYS or condition not in CONTEXT_CONDITIONS_KEYS:\n",
    "            continue\n",
    "        # Parse the LLM response\n",
    "        # Parse all rows; do NOT drop NaNs\n",
    "        parsed_series = df[col].apply(parse_llm_response)\n",
    "\n",
    "        for idx, parsed in parsed_series.items():\n",
    "            # Default to NaNs\n",
    "            rating = np.nan\n",
    "            confidence = np.nan\n",
    "            rationale = np.nan\n",
    "\n",
    "            # Accept various parse outputs\n",
    "            if isinstance(parsed, tuple):\n",
    "                # Allow (rating,), (rating, conf), or (rating, conf, rationale)\n",
    "                if len(parsed) >= 1: rating = parsed[0]\n",
    "                if len(parsed) >= 2: confidence = parsed[1]\n",
    "                if len(parsed) >= 3: rationale = parsed[2]\n",
    "            elif parsed is not None and not (isinstance(parsed, float) and pd.isna(parsed)):\n",
    "                # If parser returned a bare rating\n",
    "                rating = parsed\n",
    "\n",
    "            records.append({\n",
    "                'image_name': df.at[idx, 'image_name'],\n",
    "                'model': model,\n",
    "                'condition': condition,\n",
    "                'rating': rating,\n",
    "                'confidence': confidence,\n",
    "                'rationale': rationale\n",
    "            })\n",
    "\n",
    "    long_df = pd.DataFrame(records)\n",
    "    long_df['rating'] = pd.to_numeric(long_df['rating'], errors='coerce')\n",
    "    long_df['confidence'] = pd.to_numeric(long_df['confidence'], errors='coerce')\n",
    "    # print the unique values of model and condition\n",
    "    print(f\"Unique models: {long_df['model'].unique()}\")\n",
    "    print(f\"Unique personas: {long_df['condition'].unique()}\")\n",
    "    return long_df\n",
    "long_df = build_long_df(df, ACTIVE_MODELS_KEYS, CONTEXT_CONDITIONS_KEYS)\n",
    "\n",
    "print(\"Long DataFrame Shape:\", long_df.shape)\n",
    "print(\"First few rows of long DataFrame:\")\n",
    "print(long_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb744bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# QC -- images in long_df vs images directory\n",
    "image_files = os.listdir(image_path)\n",
    "image_names = [os.path.splitext(f)[0] for f in image_files if f.endswith(('.jpg', '.png'))]\n",
    "print(\"Unique image names in images directory:\", image_names)\n",
    "\n",
    "unique_images = long_df['image_name'].unique()\n",
    "unique_images = [os.path.splitext(img)[0] for img in unique_images]\n",
    "print(\"Unique image names after removing extensions:\", unique_images)\n",
    "missing_images = set(unique_images) - set(image_names)\n",
    "if missing_images:\n",
    "    print(\"Missing images in the images directory:\", missing_images)\n",
    "else:\n",
    "    print(\"All images in long_df are present in the images directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d73c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REJECTION RATES \n",
    "# 1) Find rows with NaN ratings\n",
    "nan_mask = long_df['rating'].isna()\n",
    "nan_rows = long_df[nan_mask].copy()\n",
    "\n",
    "# 2) Quick summary\n",
    "print(f\"NaN rating rows: {nan_rows.shape[0]} of {long_df.shape[0]} total\")\n",
    "print(\"Examples:\\n\", nan_rows.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb693d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop all images that have one or more NaN ratings\n",
    "images_with_nan = nan_rows['image_name'].unique()\n",
    "print(f\"Images with NaN ratings: {len(images_with_nan)}\")\n",
    "\n",
    "# Drop these images from the long_df\n",
    "long_df_balanced = long_df[~long_df['image_name'].isin(images_with_nan)]\n",
    "print(f\"Long DataFrame shape after dropping NaN images: {long_df_balanced.shape}\")\n",
    "long_df_balanced.to_csv(os.path.join(output_path, 'long_df_balanced.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d631dbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the long DataFrame to a CSV file drop NaNs in ratings\n",
    "long_df = long_df.dropna(subset=['rating'])\n",
    "print(f\"Long DataFrame shape after dropping NaN ratings: {long_df.shape}\")\n",
    "csv_output_path = os.path.join(output_path, 'long_df.csv')\n",
    "long_df.to_csv(csv_output_path, index=False)\n",
    "print(f\"Long DataFrame saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51362c9",
   "metadata": {},
   "source": [
    "## 2. Inter- and Intra- Annotator Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ac7413",
   "metadata": {},
   "source": [
    "### i. Krippendorff Alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01662692",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _alpha_from_pivot(pivot: pd.DataFrame) -> float:\n",
    "    \"\"\"\n",
    "    pivot: rows=items (image_name), cols=raters, values=ratings\n",
    "    Missing ratings should be NaN.\n",
    "    \"\"\"\n",
    "    # Drop items with no data at all\n",
    "    pivot = pivot.dropna(how='all')\n",
    "    # Need at least 2 raters and 2 items with some data\n",
    "    if pivot.shape[0] < 2 or pivot.shape[1] < 2:\n",
    "        return np.nan\n",
    "    data = pivot.to_numpy(dtype=float).T  # raters as rows\n",
    "    try:\n",
    "        return krippendorff.alpha(reliability_data=data, level_of_measurement='interval')\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def calculate_krippendorff_alpha(\n",
    "    long_df: pd.DataFrame,\n",
    "    mode: str = \"all\",              # \"all\", \"by_persona\", \"within_model\"\n",
    "    aggfunc = \"mean\"\n",
    ") -> Union[float, Dict[str, float]]:\n",
    "    \"\"\"\n",
    "    long_df must have columns: 'image_name', 'model', 'condition', 'rating'\n",
    "    mode:\n",
    "      - \"all\": one alpha across all models (raters=models)\n",
    "      - \"by_persona\": alpha per condition/persona (raters=models within each condition)\n",
    "      - \"within_model\": alpha per model (raters=conditions/personas within each model)\n",
    "    aggfunc: how to combine duplicates per (image, rater). Usually \"mean\".\n",
    "    \"\"\"\n",
    "    required = {\"image_name\", \"model\", \"condition\", \"rating\"}\n",
    "    missing = required - set(long_df.columns)\n",
    "    if missing:\n",
    "        raise KeyError(f\"long_df missing required columns: {missing}\")\n",
    "\n",
    "    if mode == \"all\":\n",
    "        pivot = pd.pivot_table(\n",
    "            long_df, index=\"image_name\", columns=\"model\",\n",
    "            values=\"rating\", aggfunc=aggfunc, dropna=False\n",
    "        )\n",
    "        return _alpha_from_pivot(pivot)\n",
    "\n",
    "    elif mode == \"by_persona\":\n",
    "        out: Dict[str, float] = {}\n",
    "        for persona, g in long_df.groupby(\"condition\", dropna=False):\n",
    "            pivot = pd.pivot_table(\n",
    "                g, index=\"image_name\", columns=\"model\",\n",
    "                values=\"rating\", aggfunc=aggfunc, dropna=False\n",
    "            )\n",
    "            out[persona] = _alpha_from_pivot(pivot)\n",
    "        return out\n",
    "\n",
    "    elif mode == \"within_model\":\n",
    "        out: Dict[str, float] = {}\n",
    "        for mdl, g in long_df.groupby(\"model\", dropna=False):\n",
    "            # Now raters are personas (conditions)\n",
    "            pivot = pd.pivot_table(\n",
    "                g, index=\"image_name\", columns=\"condition\",\n",
    "                values=\"rating\", aggfunc=aggfunc, dropna=False\n",
    "            )\n",
    "            out[mdl] = _alpha_from_pivot(pivot)\n",
    "        return out\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"mode must be one of: 'all', 'by_persona', 'within_model'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c050984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the Krippendorff's alpha calculation\n",
    "alpha_all = calculate_krippendorff_alpha(long_df, mode=\"all\")\n",
    "print(f\"Krippendorff's alpha (all models): {alpha_all:.4f}\")\n",
    "\n",
    "alpha_by_persona = calculate_krippendorff_alpha(long_df, mode=\"by_persona\")\n",
    "print(\"Krippendorff's alpha by persona:\")\n",
    "for persona, alpha in alpha_by_persona.items():\n",
    "    print(f\"{persona}: {alpha:.4f}\")\n",
    "\n",
    "alpha_within_model = calculate_krippendorff_alpha(long_df, mode=\"within_model\")\n",
    "print(\"Krippendorff's alpha within each model:\")\n",
    "for model, alpha in alpha_within_model.items():\n",
    "    print(f\"{model}: {alpha:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ab781e",
   "metadata": {},
   "source": [
    "### ii. ICC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe7149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_icc(long_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute Intraclass Correlation Coefficient (ICC) for rating agreement.\n",
    "    \"\"\"\n",
    "    df = long_df.pivot_table(index='image_name', columns='model', values='rating')\n",
    "    df = df.reset_index().melt(id_vars='image_name', var_name='model', value_name='rating')\n",
    "    df['image_name'] = df['image_name'].astype(str)  # Required for pingouin\n",
    "    return intraclass_corr(data=df, targets='image_name', raters='model', ratings='rating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20034cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "icc_results = compute_icc(long_df)\n",
    "print(\"Intraclass Correlation Coefficient (ICC) results comparing models:\")\n",
    "print(icc_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ec088",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_icc_by_persona(long_df: pd.DataFrame,\n",
    "                           min_raters: int = 2,\n",
    "                           balanced: bool = False,\n",
    "                           nan_policy: str = 'omit') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    ICC per condition/persona with models as raters.\n",
    "    - If balanced=False (default), uses nan_policy='omit' so unbalanced panels are OK.\n",
    "    - If balanced=True, keeps only images rated by ALL models within each persona.\n",
    "    \"\"\"\n",
    "    # 1) average duplicates so each (image, condition, model) is a single value\n",
    "    base = (long_df\n",
    "            .groupby(['image_name', 'condition', 'model'], dropna=False, as_index=False)['rating']\n",
    "            .apply(lambda s: np.nan if s.isna().all() else s.mean()))\n",
    "    base['rating'] = pd.to_numeric(base['rating'], errors='coerce')\n",
    "    base['image_name'] = base['image_name'].astype(str)\n",
    "\n",
    "    out = []\n",
    "    for cond, g in base.groupby('condition', dropna=False):\n",
    "        if balanced:\n",
    "            # keep only images with a rating from EVERY model in this persona\n",
    "            piv = g.pivot_table(index='image_name', columns='model', values='rating', aggfunc='mean')\n",
    "            piv = piv.dropna(axis=0)  # drop any image with a missing model\n",
    "            if piv.shape[0] < 2 or piv.shape[1] < 2:\n",
    "                continue\n",
    "            g2 = piv.reset_index().melt(id_vars='image_name', var_name='model', value_name='rating')\n",
    "            g2 = g2.dropna(subset=['rating'])\n",
    "            if g2['image_name'].nunique() < 2 or g2['model'].nunique() < 2:\n",
    "                continue\n",
    "            res = intraclass_corr(data=g2, targets='image_name', raters='model', ratings='rating')\n",
    "        else:\n",
    "            # allow unbalanced: keep images with at least `min_raters` ratings, let PG handle the rest\n",
    "            ok_items = g.groupby('image_name')['rating'].apply(lambda s: s.notna().sum() >= min_raters)\n",
    "            g2 = g[g['image_name'].isin(ok_items[ok_items].index)].copy()\n",
    "            g2 = g2.dropna(subset=['rating'])\n",
    "            if g2['image_name'].nunique() < 2 or g2['model'].nunique() < 2:\n",
    "                continue\n",
    "            # key change vs your version -> allow unbalanced\n",
    "            res = intraclass_corr(data=g2, targets='image_name', raters='model',\n",
    "                                  ratings='rating', nan_policy=nan_policy)\n",
    "\n",
    "        res.insert(0, 'condition', cond)\n",
    "        out.append(res)\n",
    "\n",
    "    return pd.concat(out, ignore_index=True) if out else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72feb80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unbalanced allowed (recommended; mirrors your working global ICC)\n",
    "icc_by_persona = compute_icc_by_persona(long_df, balanced=False, nan_policy='omit')\n",
    "print(icc_by_persona)\n",
    "\n",
    "# Strict sensitivity: only images rated by ALL models within each persona\n",
    "icc_by_persona_bal = compute_icc_by_persona(long_df, balanced=True)\n",
    "print(icc_by_persona_bal)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7f2fdf",
   "metadata": {},
   "source": [
    "## 3. Statistical Analysis (LRT, EMMs, Pairwise Contrasts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_df = pd.read_csv(os.path.join(output_path, 'long_df.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670b4bf2",
   "metadata": {},
   "source": [
    "### i. LRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a15d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_mixed_models(long_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Fit LMMs: full (model*condition), model-only, condition-only, and null.\n",
    "    \"\"\"\n",
    "    for col in ('model', 'condition', 'image_name'):\n",
    "        long_df[col] = long_df[col].astype('category')\n",
    "    md_full = smf.mixedlm('rating ~ model * condition', long_df, groups=long_df['image_name'])\n",
    "    res_full = md_full.fit(reml=False)\n",
    "    md_model = smf.mixedlm('rating ~ model', long_df, groups=long_df['image_name'])\n",
    "    res_model = md_model.fit(reml=False)\n",
    "    md_cond = smf.mixedlm('rating ~ condition', long_df, groups=long_df['image_name'])\n",
    "    res_cond = md_cond.fit(reml=False)\n",
    "    md_null = smf.mixedlm('rating ~ 1', long_df, groups=long_df['image_name'])\n",
    "    res_null = md_null.fit(reml=False)\n",
    "    return res_full, res_model, res_cond, res_null\n",
    "\n",
    "def lrt(res_reduced, res_full):\n",
    "    stat = 2 * (res_full.llf - res_reduced.llf)\n",
    "    df_diff = res_full.df_modelwc - res_reduced.df_modelwc\n",
    "    p = chi2.sf(stat, df_diff)\n",
    "    return stat, df_diff, p\n",
    "\n",
    "\n",
    "def run_lrt_tests(res_full, res_model, res_cond, res_null) -> pd.DataFrame:\n",
    "    tests = [\n",
    "        ('Null vs Full',    res_null,  res_full),\n",
    "        ('Null vs Model',   res_null,  res_model),\n",
    "        ('Null vs Condition',res_null, res_cond),\n",
    "        ('Model vs Full',   res_model, res_full),\n",
    "        ('Condition vs Full',res_cond, res_full),\n",
    "    ]\n",
    "    rows = []\n",
    "    for name, base, full in tests:\n",
    "        stat, df_diff, p = lrt(base, full)\n",
    "        rows.append({'Test': name, 'Chi2': stat, 'DF': df_diff, 'p-value': p})\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run LRTs across models\n",
    "res_full_all, res_model_all, res_cond_all, res_null_all = fit_mixed_models(long_df)\n",
    "cross_lrt_df = run_lrt_tests(res_full_all, res_model_all, res_cond_all, res_null_all)\n",
    "print(\"Cross-model LRT results:\")\n",
    "print(cross_lrt_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb6a2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit_ordinal_mixed_model_r(long_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Fit ordinal mixed-effects model using R's ordinal::clmm.\n",
    "    \"\"\"\n",
    "    if not R_AVAILABLE:\n",
    "        raise RuntimeError('R and required packages (ordinal) are not available')\n",
    "\n",
    "    from rpy2.robjects import r\n",
    "\n",
    "    # Push to R\n",
    "    with localconverter(pandas2ri.converter):\n",
    "        ro.globalenv['rdf'] = pandas2ri.py2rpy(long_df)\n",
    "\n",
    "    # Make sure R understands as ordered factor\n",
    "    r('rdf$rating_factor <- factor(rdf$rating, ordered=TRUE)')\n",
    "    r('rdf$model <- as.factor(rdf$model)')\n",
    "    r('rdf$condition <- as.factor(rdf$condition)')\n",
    "    r('rdf$image_name <- as.factor(rdf$image_name)')\n",
    "\n",
    "    # Fit ordinal mixed model\n",
    "    print(\"Fitting ordinal mixed-effects model...\")\n",
    "    r('library(ordinal)')\n",
    "    r('ord_fit <- clmm(rating_factor ~ model * condition + (1|image_name), data=rdf)')\n",
    "    # Text summary\n",
    "    summary_text = \"\\n\".join(list(r('capture.output(summary(ord_fit))')))\n",
    "\n",
    "    # Fixed-effects table as a pandas DataFrame\n",
    "    with localconverter(pandas2ri.converter):\n",
    "        coefs_df = r('as.data.frame(coef(summary(ord_fit)))')\n",
    "\n",
    "    return summary_text, coefs_df\n",
    "\n",
    "summary_test, coefs_df = fit_ordinal_mixed_model_r(long_df)\n",
    "print(\"Ordinal mixed-effects model summary:\")\n",
    "print(summary_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8081d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def format_clmm_table_for_supplement(coefs_df: pd.DataFrame, save_path=\"Table_S5_CLMM.csv\"):\n",
    "    \"\"\"\n",
    "    Clean, format, and export CLMM coefficients for Nature Medicine–style Supplementary Table S5.\n",
    "    Adds significance stars, bolds p<0.05 rows, and interprets direction of effects.\n",
    "    \"\"\"\n",
    "    # --- Rename columns for clarity\n",
    "    coefs_df = coefs_df.rename(columns={\n",
    "        \"Estimate\": \"β (Estimate)\",\n",
    "        \"Std. Error\": \"Std. Error\",\n",
    "        \"z value\": \"z\",\n",
    "        \"Pr(>|z|)\": \"p-value\"\n",
    "    })\n",
    "\n",
    "    # --- Filter out threshold rows (e.g., \"2|3\", \"3|4\")\n",
    "    coefs_df = coefs_df[~coefs_df.index.str.contains(r\"\\|\")].copy()\n",
    "\n",
    "    # --- Ensure numeric columns are numeric\n",
    "    numeric_cols = [\"β (Estimate)\", \"Std. Error\", \"z\", \"p-value\"]\n",
    "    coefs_df[numeric_cols] = coefs_df[numeric_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "    # --- Significance stars\n",
    "    def p_to_stars(p):\n",
    "        if p < 0.001: return '***'\n",
    "        elif p < 0.01: return '**'\n",
    "        elif p < 0.05: return '*'\n",
    "        else: return ''\n",
    "    coefs_df[\"Significance\"] = coefs_df[\"p-value\"].apply(p_to_stars)\n",
    "\n",
    "    # --- Direction of effect\n",
    "    coefs_df[\"Direction\"] = coefs_df[\"β (Estimate)\"].apply(\n",
    "        lambda b: \"Darker rating (positive)\" if b > 0 else \"Lighter rating (negative)\"\n",
    "    )\n",
    "\n",
    "    # --- Round for readability\n",
    "    coefs_df[\"β (Estimate)\"] = coefs_df[\"β (Estimate)\"].round(2)\n",
    "    coefs_df[\"Std. Error\"] = coefs_df[\"Std. Error\"].round(2)\n",
    "    coefs_df[\"z\"] = coefs_df[\"z\"].round(2)\n",
    "    coefs_df[\"p-value_display\"] = coefs_df[\"p-value\"].apply(\n",
    "        lambda p: f\"{p:.2e}\" if p < 0.001 else round(p, 3)\n",
    "    )\n",
    "\n",
    "    # --- Bold significant rows (for Markdown/HTML outputs)\n",
    "    def bold_if_sig(term, p):\n",
    "        return f\"**{term}**\" if p < 0.05 else term\n",
    "    coefs_df[\"Term_display\"] = [\n",
    "        bold_if_sig(term, p) for term, p in zip(coefs_df.index, coefs_df[\"p-value\"])\n",
    "    ]\n",
    "\n",
    "    # --- Reorder columns for clarity\n",
    "    final_cols = [\n",
    "        \"Term_display\", \"β (Estimate)\", \"Std. Error\", \"z\",\n",
    "        \"p-value_display\", \"Significance\", \"Direction\"\n",
    "    ]\n",
    "    formatted_df = coefs_df[final_cols].rename(columns={\n",
    "        \"Term_display\": \"Term\",\n",
    "        \"p-value_display\": \"p-value\"\n",
    "    })\n",
    "\n",
    "    # --- Save CSV for supplement\n",
    "    formatted_df.to_csv(save_path, index=False)\n",
    "    print(f\"Supplementary Table S5 saved to {save_path}\")\n",
    "\n",
    "    return formatted_df\n",
    "\n",
    "# Example usage:\n",
    "supp_table = format_clmm_table_for_supplement(coefs_df)\n",
    "supp_table.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f910580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "import pandas as pd\n",
    "\n",
    "def export_clmm_table_to_word(df, save_path=\"Table_S5_CLMM.docx\"):\n",
    "    doc = Document()\n",
    "    doc.add_heading(\"Supplementary Table S5\", level=1)\n",
    "    doc.add_paragraph(\n",
    "        \"Coefficients from the ordinal cumulative-link mixed model (rating ~ model × persona + (1 | image)). \"\n",
    "        \"Positive β estimates indicate darker predicted skin-tone ratings (higher Monk scale values), \"\n",
    "        \"whereas negative estimates indicate lighter predicted ratings. \"\n",
    "        \"The model used a logit link and included random intercepts for image (n = 72, SD = 1.43). \"\n",
    "        \"*p < 0.05; **p < 0.01; ***p < 0.001.*\"\n",
    "    )\n",
    "\n",
    "    # Add table\n",
    "    table = doc.add_table(rows=1, cols=len(df.columns))\n",
    "    table.style = \"Table Grid\"\n",
    "\n",
    "    # Add header row\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    for i, col_name in enumerate(df.columns):\n",
    "        hdr_cells[i].text = col_name\n",
    "\n",
    "    # Add data rows\n",
    "    for _, row in df.iterrows():\n",
    "        row_cells = table.add_row().cells\n",
    "        for i, val in enumerate(row):\n",
    "            text = str(val)\n",
    "            # Bold significant rows\n",
    "            if row[\"Significance\"] in [\"*\", \"**\", \"***\"]:\n",
    "                run = row_cells[i].paragraphs[0].add_run(text)\n",
    "                run.bold = True\n",
    "            else:\n",
    "                row_cells[i].text = text\n",
    "\n",
    "    doc.save(save_path)\n",
    "    print(f\"Word file saved: {save_path}\")\n",
    "\n",
    "formatted_df = format_clmm_table_for_supplement(coefs_df)\n",
    "export_clmm_table_to_word(formatted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c98fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Configuration helpers ----\n",
    "MODEL_MAP = {\n",
    "    \"modelGPT\": \"GPT\",\n",
    "    \"modelGemini\": \"Gemini\",\n",
    "    \"modelLlama\": \"Llama\",\n",
    "    # Claude is the reference (intercept) and thus absent as a main effect\n",
    "}\n",
    "# Optional tidy-up for condition labels\n",
    "CONDITION_RENAMES = {\n",
    "    \"cultural_asain\": \"cultural_asian\",  # fix typo if present in R output\n",
    "}\n",
    "\n",
    "def sig_stars(p):\n",
    "    try:\n",
    "        p = float(p)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    if p < 0.001: return \"***\"\n",
    "    if p < 0.01:  return \"**\"\n",
    "    if p < 0.05:  return \"*\"\n",
    "    if p < 0.1:   return \"·\"\n",
    "    return \"\"\n",
    "\n",
    "def effect_direction(beta):\n",
    "    try:\n",
    "        b = float(beta)\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    # Positive beta => higher (darker) Monk rating; Negative => lower (lighter)\n",
    "    return \"Darker (β>0)\" if b > 0 else \"Lighter (β<0)\"\n",
    "\n",
    "def prettify_condition(raw):\n",
    "    # Remove leading prefix and normalize underscores/spaces\n",
    "    c = raw\n",
    "    c = CONDITION_RENAMES.get(c, c)\n",
    "    c = re.sub(r\"^cultural_\", \"\", c)\n",
    "    c = c.replace(\"_\", \" \")\n",
    "    # small capitalizations\n",
    "    c = c.replace(\"embrace world\", \"embrace world-knowledge\")\n",
    "    c = c.replace(\"ignore world\", \"ignore world-knowledge\")\n",
    "    return c\n",
    "\n",
    "def categorize_terms(coefs_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    coefs_df is the result of:\n",
    "      coefs_df = r('as.data.frame(coef(summary(ord_fit)))')\n",
    "    Row names contain term labels (e.g., 'modelGPT', 'conditioncultural_darker', 'modelLlama:conditioncultural_lighter')\n",
    "    \"\"\"\n",
    "    df = coefs_df.copy()\n",
    "\n",
    "    # Ensure term labels are available as a column\n",
    "    if df.index.name is None or df.index.name == \"\":\n",
    "        df.index.name = \"Term\"\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    # Standardize column names coming from R\n",
    "    rename_map = {\n",
    "        \"Estimate\": \"beta\",\n",
    "        \"Std. Error\": \"SE\",\n",
    "        \"z value\": \"z\",\n",
    "        \"Pr(>|z|)\": \"p\"\n",
    "    }\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    # Work on numeric copies for sorting/formatting later\n",
    "    for col in [\"beta\", \"SE\", \"z\", \"p\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # Categorize & extract parts\n",
    "    term_type = []\n",
    "    model_label = []\n",
    "    persona_label = []\n",
    "\n",
    "    for t in df[\"Term\"]:\n",
    "        if \":\" in t:\n",
    "            term_type.append(\"Model×Persona interaction\")\n",
    "            m, c = t.split(\":\", 1)\n",
    "            model_label.append(MODEL_MAP.get(m, m.replace(\"model\", \"\")))\n",
    "            c = c.replace(\"condition\", \"\")\n",
    "            persona_label.append(prettify_condition(c))\n",
    "        elif t.startswith(\"model\"):\n",
    "            term_type.append(\"Model main effect\")\n",
    "            model_label.append(MODEL_MAP.get(t, t.replace(\"model\", \"\")))\n",
    "            persona_label.append(\"\")\n",
    "        elif t.startswith(\"condition\"):\n",
    "            term_type.append(\"Persona main effect (Claude ref.)\")\n",
    "            model_label.append(\"Claude (ref.)\")\n",
    "            c = t.replace(\"condition\", \"\")\n",
    "            persona_label.append(prettify_condition(c))\n",
    "        else:\n",
    "            term_type.append(\"Other\")\n",
    "            model_label.append(\"\")\n",
    "            persona_label.append(\"\")\n",
    "\n",
    "    df[\"Category\"] = term_type\n",
    "    df[\"Model\"] = model_label\n",
    "    df[\"Persona\"] = persona_label\n",
    "\n",
    "    # Add interpretation columns\n",
    "    df[\"Direction\"] = df[\"beta\"].apply(effect_direction)\n",
    "    df[\"Sig\"] = df[\"p\"].apply(sig_stars)\n",
    "\n",
    "    # Pretty numeric formatting for supplement\n",
    "    def fmt(x, dec=2):\n",
    "        if pd.isna(x): return \"\"\n",
    "        # show very small p-values as scientific\n",
    "        if isinstance(x, float) and (x < 0.001) and (x >= 0):\n",
    "            return f\"{x:.2e}\"\n",
    "        return f\"{x:.{dec}f}\"\n",
    "\n",
    "    df[\"β (Estimate)\"] = df[\"beta\"].apply(fmt)\n",
    "    df[\"Std. Error\"] = df[\"SE\"].apply(fmt)\n",
    "    df[\"z\"] = df[\"z\"].apply(fmt)\n",
    "    df[\"p-value\"] = df[\"p\"].apply(lambda x: \"<0.001\" if (pd.notna(x) and x < 0.001) else fmt(x, 3))\n",
    "\n",
    "    # Arrange columns\n",
    "    cols = [\n",
    "        \"Category\", \"Model\", \"Persona\", \"Term\",\n",
    "        \"β (Estimate)\", \"Std. Error\", \"z\", \"p-value\", \"Sig\", \"Direction\"\n",
    "    ]\n",
    "    df_out = df[cols].copy()\n",
    "\n",
    "    # Sort within categories by p-value ascending\n",
    "    df_out[\"p_sort\"] = pd.to_numeric(df[\"p\"], errors=\"coerce\")\n",
    "    df_out.sort_values(by=[\"Category\", \"p_sort\"], inplace=True)\n",
    "    df_out.drop(columns=[\"p_sort\"], inplace=True)\n",
    "\n",
    "    return df_out\n",
    "\n",
    "def export_grouped_tables(df_out: pd.DataFrame, base_path=\"supp_table_CLMM\"):\n",
    "    \"\"\"Save overall and per-category CSVs for the supplement.\"\"\"\n",
    "    df_out.to_csv(f\"{base_path}_all.csv\", index=False)\n",
    "    for cat, sub in df_out.groupby(\"Category\"):\n",
    "        safe = re.sub(r\"[^A-Za-z0-9]+\", \"_\", cat).strip(\"_\").lower()\n",
    "        sub.to_csv(f\"{base_path}_{safe}.csv\", index=False)\n",
    "    print(\"Saved:\")\n",
    "    print(f\" - {base_path}_all.csv\")\n",
    "    print(f\" - {base_path}_model_main_effect.csv\")\n",
    "    print(f\" - {base_path}_persona_main_effect_claude_ref_.csv\")\n",
    "    print(f\" - {base_path}_model_persona_interaction.csv\")\n",
    "\n",
    "# ---- Usage (after you already computed coefs_df) ----\n",
    "df_out = categorize_terms(coefs_df)\n",
    "export_grouped_tables(df_out, base_path=\"supp_table_CLMM\")\n",
    "df_out  # preview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3717f8",
   "metadata": {},
   "source": [
    "### ii. EMMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da0cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emmeans_r(long_df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Compute EMMs and pairwise contrasts via R's lme4 + emmeans.\n",
    "    Returns dict with 'emms' and 'contrasts' DataFrames, with model & condition as strings.\n",
    "    \"\"\"\n",
    "    if not R_AVAILABLE:\n",
    "        raise RuntimeError('R and required packages (lme4, emmeans) are not available')\n",
    "\n",
    "    with localconverter(pandas2ri.converter):\n",
    "        ro.globalenv['rdf'] = pandas2ri.py2rpy(long_df)\n",
    "    # Ensure factors in R\n",
    "    ro.r('rdf$condition <- as.factor(rdf$condition)')\n",
    "    ro.r('rdf$image_name <- as.factor(rdf$image_name)')\n",
    "    ro.r('rdf$model <- as.factor(rdf$model)')\n",
    "    # Choose formula and EMM basis\n",
    "    n_models = long_df['model'].nunique()\n",
    "    n_conditions = long_df['condition'].nunique()\n",
    "    if n_models > 1 and n_conditions > 1:\n",
    "        r_formula, emm_by = 'rating ~ model * condition', '~ model | condition'\n",
    "    elif n_models > 1:\n",
    "        #r_formula, emm_by = 'rating ~ model', '~ model'\n",
    "        r_formula, emm_by = 'rating ~ condition * model', '~ condition | model' # Edies change for interaction effects \"does the persona effect depend on the model\"\n",
    "    else:\n",
    "        r_formula, emm_by = 'rating ~ condition', '~ condition'\n",
    "    # Fit the mixed model in R\n",
    "    ro.r(f\"fit <- lme4::lmer({r_formula} + (1|image_name), data=rdf)\")\n",
    "    # Compute emmeans\n",
    "    ro.r(f\"emm <- emmeans::emmeans(fit, {emm_by})\")\n",
    "    # Convert to data frame and coerce factors to strings\n",
    "    ro.r('emm_df <- as.data.frame(emm)')\n",
    "    ro.r('if(\"model\" %in% colnames(emm_df)) emm_df$model <- as.character(emm_df$model)')\n",
    "    ro.r('emm_df$condition <- as.character(emm_df$condition)')\n",
    "    # Compute pairwise contrasts\n",
    "    ro.r('cont_df <- as.data.frame(contrast(emm, method=\"pairwise\", adjust=\"holm\"))')\n",
    "    ro.r('if(\"model\" %in% colnames(cont_df)) cont_df$model <- as.character(cont_df$model)')\n",
    "\n",
    "    # condition-by-model EMMs & contrasts (persona contrasts within each model)\n",
    "    ro.r('emm_cond_by_model <- emmeans::emmeans(fit, ~ condition | model)')\n",
    "    ro.r('cont_cond_by_model <- as.data.frame(emmeans::contrast(emm_cond_by_model, '\n",
    "         '                                      method=\"pairwise\", adjust=\"holm\"))')\n",
    "    # ADD these two lines:\n",
    "    ro.r('cont_cond_by_model$contrast <- as.character(cont_cond_by_model$contrast)')\n",
    "    ro.r('cont_cond_by_model$model <- as.character(cont_cond_by_model$model)')\n",
    "\n",
    "    # Convert back to pandas\n",
    "    with localconverter(pandas2ri.converter):\n",
    "        py_emms = r('emm_df')\n",
    "        py_cont = r('cont_df')\n",
    "        py_cont_cond_by_model = r('cont_cond_by_model')\n",
    "    return {'emms': py_emms, 'contrasts': py_cont, 'contrasts_cond_by_model': py_cont_cond_by_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b4d341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute EMMs + contrasts across models\n",
    "res = compute_emmeans_r(long_df)\n",
    "emm_df = res['emms']\n",
    "contr_df = res['contrasts']\n",
    "cross_emms_path = os.path.join(output_path, 'cross_model_emms.csv')\n",
    "cross_cont_path = os.path.join(output_path, 'cross_model_contrasts.csv')\n",
    "emm_df.to_csv(cross_emms_path, index=False)\n",
    "contr_df.to_csv(cross_cont_path, index=False)\n",
    "print(f'Saved cross-model EMMs to {cross_emms_path}')\n",
    "print(f'Saved cross-model contrasts to {cross_cont_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22557f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_contrasts(contr_df, alpha=0.05):\n",
    "    out = []\n",
    "    for cond, g in contr_df.groupby('condition'):\n",
    "        sig = g[g['p.value'] < alpha].copy()\n",
    "        sig['CI_low']  = sig['estimate'] - 1.96 * sig['SE']\n",
    "        sig['CI_high'] = sig['estimate'] + 1.96 * sig['SE']\n",
    "        out.append((cond, sig.sort_values('p.value')[['contrast','estimate','SE','CI_low','CI_high','z.ratio','p.value']]))\n",
    "    return out\n",
    "\n",
    "# usage\n",
    "for cond, tbl in summarize_contrasts(contr_df):\n",
    "     print(f\"\\n[{cond}] significant pairwise model differences:\")\n",
    "     print(tbl.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0041016",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def make_persona_pair_table(contr_cbm: pd.DataFrame, alpha=0.05, min_models=3, add_ci=True):\n",
    "    \"\"\"\n",
    "    Build 'Table 2' of persona-vs-persona contrasts within each model\n",
    "    from emmeans(fit, ~ condition | model).\n",
    "\n",
    "    - Keeps only persona pairs that are significant (Holm-adjusted p) in >= min_models models.\n",
    "    - Final table includes ONLY rows that are themselves significant (p < alpha).\n",
    "    - Optionally adds 95% CIs (normal approx).\n",
    "    \"\"\"\n",
    "    # Normalize names from emmeans\n",
    "    df = contr_cbm.rename(columns={\n",
    "        'p.value': 'p_value',\n",
    "        'SE': 'SE',\n",
    "        'estimate': 'estimate',\n",
    "        'model': 'Model',\n",
    "        'contrast': 'contrast',\n",
    "    }).copy()\n",
    "\n",
    "    # Required columns\n",
    "    needed = {'Model', 'contrast', 'estimate', 'SE', 'p_value'}\n",
    "    missing = needed - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing columns from contrasts_cond_by_model: {missing}\")\n",
    "\n",
    "    # Types\n",
    "    df['contrast'] = df['contrast'].astype(str)\n",
    "    df['Model']    = df['Model'].astype(str)\n",
    "    df['p_value']  = pd.to_numeric(df['p_value'], errors='coerce')\n",
    "    df['estimate'] = pd.to_numeric(df['estimate'], errors='coerce')\n",
    "    df['SE']       = pd.to_numeric(df['SE'], errors='coerce')\n",
    "\n",
    "    # Persona-pair label (emmeans uses \"A - B\")\n",
    "    df['Contrast'] = df['contrast'].str.replace(' - ', ' vs ', regex=False)\n",
    "\n",
    "    # Mark significance\n",
    "    df['sig'] = df['p_value'] < alpha\n",
    "\n",
    "    # Count how many UNIQUE models are significant for each persona pair\n",
    "    sig_counts = (df[df['sig']]\n",
    "                  .groupby('Contrast')['Model']\n",
    "                  .nunique()\n",
    "                  .reset_index(name='models_sig'))\n",
    "\n",
    "    # Keep persona pairs with >= min_models significant models\n",
    "    keep_pairs = set(sig_counts.loc[sig_counts['models_sig'] >= min_models, 'Contrast'])\n",
    "\n",
    "    # Filter to kept pairs AND only significant rows\n",
    "    out = df[(df['Contrast'].isin(keep_pairs)) & (df['sig'])].copy()\n",
    "\n",
    "    # Optional 95% CIs (z approx)\n",
    "    if add_ci:\n",
    "        z = 1.96\n",
    "        out['CI_low']  = out['estimate'] - z * out['SE']\n",
    "        out['CI_high'] = out['estimate'] + z * out['SE']\n",
    "\n",
    "    # Final columns / order\n",
    "    cols = ['Contrast', 'Model', 'estimate', 'SE', 'p_value']\n",
    "    if add_ci:\n",
    "        cols = ['Contrast', 'Model', 'estimate', 'SE', 'CI_low', 'CI_high', 'p_value']\n",
    "\n",
    "    out = (out[cols]\n",
    "           .rename(columns={'estimate':'Estimate', 'p_value':'p-value', 'SE':'SE'})\n",
    "           .sort_values(['Contrast', 'Model'])\n",
    "           .reset_index(drop=True))\n",
    "\n",
    "    # Formatting\n",
    "    for c in ['Estimate', 'SE']:\n",
    "        out[c] = out[c].round(2)\n",
    "    if add_ci:\n",
    "        out['CI_low']  = out['CI_low'].round(2)\n",
    "        out['CI_high'] = out['CI_high'].round(2)\n",
    "    out['p-value'] = out['p-value'].apply(lambda x: f\"{float(x):.3f}\" if pd.notnull(x) else \"NA\")\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "contr_cbm = res['contrasts_cond_by_model']\n",
    "table2 = make_persona_pair_table(contr_cbm, alpha=0.05)\n",
    "table2.to_csv('table2_persona_pairwise_contrasts.csv', index=False)\n",
    "print(table2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec82c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting EMMs\n",
    "\n",
    "def plot_emms_r(emms_df: pd.DataFrame, save_path: str = None, model_name: str = None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Define color mapping for model families\n",
    "    model_colors = {\n",
    "        'GPT': '#2ecc71',    # Green\n",
    "        'Claude': '#e74c3c', # Red\n",
    "        'Llama': '#3498db',  # Blue\n",
    "        'Gemini': '#f1c40f', # Yellow\n",
    "    }\n",
    "\n",
    "    # Mapping for cleaned persona names\n",
    "    condition_map = {\n",
    "        'cultural_africanamerican': 'African American',\n",
    "        'cultural_asain': 'Asian',\n",
    "        'cultural_hispanic': 'Hispanic',\n",
    "        'cultural_indigenous': 'Indigenous',\n",
    "        'cultural_colorism': 'Experienced Colorism',\n",
    "        'cultural_white': 'White',\n",
    "        'baseline': 'Baseline',\n",
    "        'cultural_black': 'Black',\n",
    "        'cultural_lighter': 'Grew up in a Lighter Skin Toned Community',\n",
    "        'cultural_darker': 'Grew up in a Darker Skin Toned Community',\n",
    "        'embrace_world': 'Embrace all World Knowledge',\n",
    "        'ignore_world': 'Ignore all World Knowledge',\n",
    "    }\n",
    "    emms_df['condition_clean'] = emms_df['condition'].map(condition_map).fillna(emms_df['condition'])\n",
    "    # Build an order with Baseline first, others alphabetical (customize if you want)\n",
    "    all_conditions = sorted(set(emms_df['condition_clean']) - {'Baseline'})\n",
    "    persona_order = ['Baseline'] + all_conditions\n",
    "\n",
    "    # Make it an ordered categorical so sorting respects this order\n",
    "    emms_df['condition_clean'] = pd.Categorical(\n",
    "        emms_df['condition_clean'],\n",
    "        categories=persona_order,\n",
    "        ordered=True\n",
    "    )\n",
    "    print(\"Unique conditions after mapping:\", emms_df['condition_clean'].unique())\n",
    "    if model_name == 'All Models':\n",
    "        # Plot for All Models\n",
    "        fig, ax = plt.subplots(figsize=(15, 6))\n",
    "        emms_df = emms_df.sort_values(['model', 'condition_clean'])\n",
    "        models = emms_df['model'].unique()\n",
    "        x_positions = []\n",
    "        labels = []\n",
    "        x = 0\n",
    "        model_boundaries = []\n",
    "\n",
    "        for model in models:\n",
    "            model_data = emms_df[emms_df['model'] == model]\n",
    "            start_x = x\n",
    "            for _, row in model_data.iterrows():\n",
    "                model_family = next((family for family in model_colors if family.lower() in row['model'].lower()), 'Other')\n",
    "                color = model_colors.get(model_family, '#95a5a6')\n",
    "                ax.errorbar(x, row['emmean'], yerr=row['SE'], fmt='o', capsize=5, color=color)\n",
    "                labels.append(row['condition_clean'])\n",
    "                x_positions.append(x)\n",
    "                x += 1\n",
    "            end_x = x - 1\n",
    "            mid_x = (start_x + end_x) / 2\n",
    "            model_boundaries.append((x, mid_x, model))\n",
    "            x += 1  # gap\n",
    "\n",
    "        # X/Y Labels and ticks\n",
    "        ax.set_xticks(x_positions)\n",
    "        ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "        #ax.set_ylabel('Estimated Marginal Mean (EMM)')\n",
    "        ax.set_ylabel('EMM of Monk Skin Tone Rating (1-10)')\n",
    "        ax.set_title('Estimated Marginal Means (EMM) within Personas Grouped by Model')\n",
    "\n",
    "        # Add vertical dashed lines between models\n",
    "        for boundary, _, _ in model_boundaries[:-1]:  # skip last\n",
    "            ax.axvline(x=boundary - 0.5, color='gray', linestyle='--', alpha=0.3)\n",
    "        \n",
    "        # Add model labels at top inside plot\n",
    "        ax.set_ylim(1, 10)\n",
    "        ylim = ax.get_ylim()\n",
    "        y_top = ylim[1] - 0.1 * (ylim[1] - ylim[0])\n",
    "        for _, mid_x, model in model_boundaries:\n",
    "            ax.text(mid_x, y_top, model,\n",
    "                    fontsize=10, fontweight='bold',\n",
    "                    va='bottom', ha='center',\n",
    "                    bbox=dict(facecolor='white', edgecolor='black', boxstyle='round'))\n",
    "\n",
    "        #ax.set_ylim(ylim[0], y_top + 0.05 * (ylim[1] - ylim[0]))\n",
    "        # set y-axis 1-10\n",
    "        \n",
    "\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "    else:\n",
    "        # Plot for individual model\n",
    "        labels = emms_df['condition'].map(condition_map).fillna(emms_df['condition']).tolist()\n",
    "        x_positions = range(len(labels))\n",
    "        plt.errorbar(x_positions, emms_df['emmean'], yerr=emms_df['SE'], fmt='o', capsize=5)\n",
    "        plt.xticks(x_positions, labels, rotation=45, ha='right')\n",
    "        plt.xlabel('Persona')\n",
    "        plt.ylabel('EMM')\n",
    "        title = 'Estimated Marginal Means'\n",
    "        if model_name:\n",
    "            title += f' - {model_name}'\n",
    "        plt.title(title)\n",
    "        plt.tight_layout()\n",
    "        if save_path:\n",
    "            plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def plot_emms_by_persona(emms_df: pd.DataFrame, save_path: str = None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Define color mapping for model families\n",
    "    model_colors = {\n",
    "        'GPT': '#2ecc71',    # Green\n",
    "        'Claude': '#e74c3c', # Red\n",
    "        'Llama': '#3498db',  # Blue\n",
    "        'Gemini': '#f1c40f', # Yellow\n",
    "    }\n",
    "\n",
    "    # Mapping for cleaned persona names\n",
    "    condition_map = {\n",
    "        'cultural_africanamerican': 'African American',\n",
    "        'cultural_asain': 'Asian',\n",
    "        'cultural_hispanic': 'Hispanic',\n",
    "        'cultural_indigenous': 'Indigenous',\n",
    "        'cultural_colorism': 'Experienced Colorism',\n",
    "        'cultural_white': 'White',\n",
    "        'baseline': 'Baseline',\n",
    "        'cultural_black': 'Black',\n",
    "        'cultural_lighter': 'Grew up in a Lighter Skin Toned Community',\n",
    "        'cultural_darker': 'Grew up in a Darker Skin Toned Community',\n",
    "        'embrace_world': 'Embrace all World Knowledge',\n",
    "        'ignore_world': 'Ignore all World Knowledge',\n",
    "    }\n",
    "    emms_df['condition_clean'] = emms_df['condition'].map(condition_map).fillna(emms_df['condition'])\n",
    "\n",
    "    # Sort the dataframe by condition and model\n",
    "    emms_df = emms_df.sort_values(['condition_clean', 'model'])\n",
    "    conditions = emms_df['condition_clean'].unique()\n",
    "    models = emms_df['model'].unique()\n",
    "    \n",
    "    x_positions = []\n",
    "    label_positions = []\n",
    "    labels = []\n",
    "    current_x = 0\n",
    "    persona_boundaries = []\n",
    "\n",
    "    for condition in conditions:\n",
    "        condition_data = emms_df[emms_df['condition_clean'] == condition]\n",
    "        start_x = current_x\n",
    "        for model in models:\n",
    "            if model in condition_data['model'].values:\n",
    "                x_positions.append(current_x)\n",
    "                current_x += 1\n",
    "        end_x = current_x - 1\n",
    "        mid_x = (start_x + end_x) / 2\n",
    "        label_positions.append(mid_x)\n",
    "        labels.append(condition)\n",
    "        persona_boundaries.append((start_x, end_x))\n",
    "        current_x += 1\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(15, 6))\n",
    "    \n",
    "    for i, (_, row) in enumerate(emms_df.iterrows()):\n",
    "        model_family = next((family for family in model_colors.keys()\n",
    "                             if family.lower() in row['model'].lower()), 'Other')\n",
    "        color = model_colors.get(model_family, '#95a5a6')\n",
    "        ax.errorbar(x_positions[i], row['emmean'], yerr=row['SE'], \n",
    "                    fmt='o', capsize=5, color=color,\n",
    "                    label=row['model'] if i == 0 or row['model'] not in [l.get_label() for l in plt.gca().lines] else \"\")\n",
    "\n",
    "    # Add vertical dashed lines between personas\n",
    "    for start_x, end_x in persona_boundaries[:-1]:\n",
    "        ax.axvline(x=end_x + 0.5, color='gray', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    #ax.set_ylim(bottom=ax.get_ylim()[0])  # keep default bottom\n",
    "    ax.set_ylim(1, 10)  # set y-axis 1-10\n",
    "    #ax.set_ylabel('Estimated Marginal Mean (EMM)')\n",
    "    ax.set_ylabel('EMM of Monk Skin Tone Rating (1-10)')\n",
    "    ax.set_xticks(label_positions)\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "    ax.set_title('Estimated Marginal Means (EMM) - Grouped by Persona')\n",
    "\n",
    "    # Add color-coded legend for model families\n",
    "    unique_models = emms_df['model'].unique()\n",
    "    handles = []\n",
    "    for model in unique_models:\n",
    "        model_family = next((family for family in model_colors if family.lower() in model.lower()), 'Other')\n",
    "        color = model_colors.get(model_family, '#95a5a6')\n",
    "        handles.append(plt.Line2D([0], [0], marker='o', color='w',\n",
    "                                  markerfacecolor=color, markersize=10, label=model))\n",
    "    ax.legend(handles=handles, bbox_to_anchor=(1.02, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n",
    "def plot_emms_superimposed(emms_df: pd.DataFrame, save_path: str = None, model_name: str = 'All Models'):\n",
    "    \"\"\"\n",
    "    Plots EMMs superimposed by persona (x-axis = persona), color-coded by model.\n",
    "    - All circular points, no connecting lines, aligned on same vertical line per persona.\n",
    "    - Legend shows dots only (no error bars).\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from itertools import cycle\n",
    "    import matplotlib.lines as mlines\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Color mapping for model families\n",
    "    model_colors = {\n",
    "        'GPT': '#2ecc71',    # Green\n",
    "        'Claude': '#e74c3c', # Red\n",
    "        'Llama': '#3498db',  # Blue\n",
    "        'Gemini': '#f1c40f', # Yellow\n",
    "    }\n",
    "    default_palette = ['#8e44ad', '#16a085', '#d35400', '#2c3e50', '#7f8c8d']\n",
    "\n",
    "    # Mapping for cleaned persona names\n",
    "    condition_map = {\n",
    "        'cultural_africanamerican': 'African American',\n",
    "        'cultural_asain': 'Asian',\n",
    "        'cultural_hispanic': 'Hispanic',\n",
    "        'cultural_indigenous': 'Indigenous',\n",
    "        'cultural_colorism': 'Experienced Colorism',\n",
    "        'cultural_white': 'White',\n",
    "        'baseline': 'Baseline',\n",
    "        'cultural_black': 'Black',\n",
    "        'cultural_lighter': 'Grew up in a Lighter Skin Toned Community',\n",
    "        'cultural_darker': 'Grew up in a Darker Skin Toned Community',\n",
    "        'embrace_world': 'Embrace all World Knowledge',\n",
    "        'ignore_world': 'Ignore all World Knowledge',\n",
    "    }\n",
    "\n",
    "    # Create cleaned persona column\n",
    "    emms_df = emms_df.copy()\n",
    "    emms_df['condition_clean'] = emms_df['condition'].map(condition_map).fillna(emms_df['condition'])\n",
    "\n",
    "    # Build persona order: Baseline first, then alphabetical\n",
    "    all_conditions = sorted(set(emms_df['condition_clean']) - {'Baseline'})\n",
    "    persona_order = ['Baseline'] + all_conditions\n",
    "    emms_df['condition_clean'] = pd.Categorical(emms_df['condition_clean'],\n",
    "                                               categories=persona_order,\n",
    "                                               ordered=True)\n",
    "\n",
    "    # Filter if a single model requested\n",
    "    if model_name != 'All Models':\n",
    "        emms_df = emms_df[emms_df['model'] == model_name]\n",
    "\n",
    "    # Determine unique personas and models (keep persona order)\n",
    "    personas = [p for p in persona_order if p in emms_df['condition_clean'].unique()]\n",
    "    models = sorted(emms_df['model'].unique())\n",
    "\n",
    "    if len(models) == 0 or len(personas) == 0:\n",
    "        raise ValueError(\"No data to plot: check 'model_name' filter and that 'condition' values exist in the dataframe.\")\n",
    "\n",
    "    # x positions for personas (categorical)\n",
    "    x_positions = np.arange(len(personas))\n",
    "\n",
    "    # Prepare color mapping for each model\n",
    "    model_to_color = {}\n",
    "    default_cycle = cycle(default_palette)\n",
    "    for m in models:\n",
    "        family = next((family for family in model_colors if family.lower() in m.lower()), None)\n",
    "        model_to_color[m] = model_colors.get(family, next(default_cycle))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "    # Plot each model’s points (all aligned on same x positions)\n",
    "    for model in models:\n",
    "        model_df = emms_df[emms_df['model'] == model]\n",
    "        means, ses = [], []\n",
    "        for persona in personas:\n",
    "            row = model_df[model_df['condition_clean'] == persona]\n",
    "            if not row.empty:\n",
    "                means.append(float(row['emmean'].iloc[0]))\n",
    "                ses.append(float(row['SE'].iloc[0]))\n",
    "            else:\n",
    "                means.append(np.nan)\n",
    "                ses.append(np.nan)\n",
    "\n",
    "        valid = ~np.isnan(means)\n",
    "        if valid.any():\n",
    "            ax.errorbar(x_positions[valid], np.array(means)[valid],\n",
    "                        yerr=np.array(ses)[valid],\n",
    "                        fmt='o', capsize=4,\n",
    "                        color=model_to_color[model],\n",
    "                        markersize=6, alpha=0.9)\n",
    "\n",
    "    # X-axis labels (only personas)\n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(personas, rotation=45, ha='right', fontsize=10)\n",
    "\n",
    "    ax.set_ylabel('EMM of Monk Skin Tone Rating (1–10)')\n",
    "    ax.set_title('Estimated Marginal Means by Persona — Models Superimposed')\n",
    "\n",
    "    # Y limits consistent with your 1–10 scale\n",
    "    ax.set_ylim(1, 10)\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "\n",
    "    # --- Custom legend: dots only (no error bars) ---\n",
    "    legend_handles = [\n",
    "        mlines.Line2D([], [], color=color, marker='o', linestyle='None', markersize=6, label=model)\n",
    "        for model, color in model_to_color.items()\n",
    "    ]\n",
    "    ax.legend(handles=legend_handles, title='Model',\n",
    "              bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84a635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot cross-model EMMs\n",
    "emms = res[\"emms\"].copy()          # columns should include: model, condition, emmean, SE\n",
    "contrasts = res[\"contrasts\"].copy()\n",
    "\n",
    "#save the EMMs and contrasts to CSV files\n",
    "emms.to_csv(os.path.join(output_path, 'cross_model_emms.csv'), index=False)\n",
    "contrasts.to_csv(os.path.join(output_path, 'cross_model_contrasts.csv'), index=False)\n",
    "\n",
    "cross_plot_path = os.path.join(output_path, 'cross_model_emms.png')\n",
    "plot_emms_r(emms, cross_plot_path, model_name='All Models')\n",
    "print(f'Saved cross-model EMM plot to {cross_plot_path}')\n",
    "\n",
    "# # After the original cross-model EMMs plot, add:\n",
    "# # Plot cross-model EMMs grouped by persona\n",
    "cross_plot_persona_path = os.path.join(output_path, 'cross_model_emms_by_persona.png')\n",
    "plot_emms_by_persona(emms, cross_plot_persona_path)\n",
    "print(f'Saved cross-model EMM plot (grouped by persona) to {cross_plot_persona_path}')\n",
    "\n",
    "# new superimposed plot\n",
    "cross_plot_superimposed_path = os.path.join(output_path, 'cross_model_emms_superimposed.png')\n",
    "plot_emms_superimposed(emms, cross_plot_superimposed_path, model_name='All Models')\n",
    "print(f'Saved cross-model EMM superimposed plot to {cross_plot_superimposed_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507f1bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def persona_consistency_percent_from_emms(emms: pd.DataFrame,\n",
    "                                          baseline_label: str = \"baseline\",\n",
    "                                          require_all_models: bool = True):\n",
    "    \"\"\"\n",
    "    Compute the % of personas where all models' effects vs baseline go in the same direction.\n",
    "    - emms: DataFrame with columns ['model','condition','emmean'] (from emmeans)\n",
    "    - baseline_label: value in 'condition' that represents the baseline\n",
    "    - require_all_models: if True, only evaluate personas that have *all* models present\n",
    "                          both at baseline and at that persona. If False, allow partial overlap (>=2 models).\n",
    "    Returns: (percent_consistent, details_df)\n",
    "    \"\"\"\n",
    "    df = emms[['model','condition','emmean']].copy()\n",
    "    df['model'] = df['model'].astype(str)\n",
    "    df['condition'] = df['condition'].astype(str)\n",
    "\n",
    "    # Baseline EMM per model\n",
    "    base = (df[df['condition'] == baseline_label]\n",
    "              .rename(columns={'emmean':'baseline_emm'})\n",
    "              [['model','baseline_emm']])\n",
    "\n",
    "    # Merge baseline back\n",
    "    merged = df.merge(base, on='model', how='left')\n",
    "    merged['effect_vs_base'] = merged['emmean'] - merged['baseline_emm']\n",
    "\n",
    "    # Exclude the baseline rows from evaluation\n",
    "    eval_df = merged[merged['condition'] != baseline_label].copy()\n",
    "\n",
    "    # Helper to decide consistency for one persona\n",
    "    def persona_consistency(g: pd.DataFrame):\n",
    "        # drop NaNs and exact zeros (neutral) for direction check\n",
    "        vals = g['effect_vs_base'].to_numpy(dtype=float)\n",
    "        vals = vals[np.isfinite(vals)]\n",
    "        nonzero = vals[~np.isclose(vals, 0.0)]\n",
    "        # check coverage\n",
    "        models_present = g['model'].nunique()\n",
    "        models_needed = base['model'].nunique() if require_all_models else 2\n",
    "        if models_present < models_needed:\n",
    "            return 'insufficient'\n",
    "        if nonzero.size == 0:\n",
    "            return 'neutral'  # no directional change\n",
    "        all_pos = np.all(nonzero > 0)\n",
    "        all_neg = np.all(nonzero < 0)\n",
    "        return 'consistent' if (all_pos or all_neg) else 'inconsistent'\n",
    "\n",
    "    # Evaluate per persona\n",
    "    status = (eval_df.groupby('condition', as_index=False)\n",
    "                     .apply(persona_consistency)\n",
    "                     .rename(columns={None:'status'})  # pandas <2.1 behavior\n",
    "              )\n",
    "    status.columns = ['condition','status']  # ensure names\n",
    "\n",
    "    # Compute percentage over evaluable personas\n",
    "    evaluable = status[status['status'].isin(['consistent','inconsistent','neutral'])]\n",
    "    if len(evaluable) == 0:\n",
    "        percent = np.nan\n",
    "    else:\n",
    "        percent = 100.0 * (evaluable['status'].eq('consistent').sum() / len(evaluable))\n",
    "\n",
    "    return percent, status.sort_values('condition')\n",
    "\n",
    "\n",
    "emms = res['emms']\n",
    "pct, table = persona_consistency_percent_from_emms(emms, baseline_label=\"baseline\", require_all_models=True)\n",
    "print(f\"Consistent persona effects: {pct:.1f}%\")\n",
    "display(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886c6afe",
   "metadata": {},
   "source": [
    "## 4. Qualitative Analysis of LLM Rationales "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cbf94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check long df rational for all models???\n",
    "long_df = pd.read_csv(os.path.join(output_path, 'long_df.csv'))\n",
    "\n",
    "# count rationales for each model \n",
    "def count_rationales(long_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Count the number of rationales provided by each model.\n",
    "    Assumes 'rationale' column exists in long_df.\n",
    "    \"\"\"\n",
    "    if 'rationale' not in long_df.columns:\n",
    "        raise KeyError(\"long_df must contain a 'rationale' column.\")\n",
    "    \n",
    "    # Create a new column to indicate if a rationale was provided\n",
    "    long_df['has_rationale'] = long_df['rationale'].notna() & (long_df['rationale'].str.strip() != '')\n",
    "    \n",
    "    # Group by model and count rationales\n",
    "    rationale_counts = (long_df.groupby('model')['has_rationale']\n",
    "                        .sum()\n",
    "                        .reset_index()\n",
    "                        .rename(columns={'has_rationale': 'rationale_count'}))\n",
    "    \n",
    "    return rationale_counts\n",
    "rationale_counts = count_rationales(long_df)\n",
    "print(\"Rationale counts by model:\")\n",
    "print(rationale_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c649cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, pandas as pd\n",
    "from sympy import denom\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# -------------------------\n",
    "# 1) Prep\n",
    "# -------------------------\n",
    "def get_rationales(long_df):\n",
    "    cols = ['model','condition','image_name','rating','rationale']\n",
    "    df = long_df[cols].copy()\n",
    "    df['rationale'] = df['rationale'].fillna('').astype(str).str.strip()\n",
    "    return df[df['rationale']!=''].reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# 2) Lexicons / detectors\n",
    "# -------------------------\n",
    "HEDGES = r'\\b(might|may|could|possibly|perhaps|appears|seems|likely|suggests)\\b'\n",
    "\n",
    "# Broadened disclaimer detector\n",
    "DISCLAIMER = (\n",
    "    r\"\\b(as (an )?(ai|language model))\\b|\"\n",
    "    r\"\\b(i\\s*(cannot|can't|do not|don't|am unable|i’m unable|i am unable|won't|will not))\\b|\"\n",
    "    r\"\\b(i (don'?t|do not) have (enough )?(info|information|access|the ability))\\b|\"\n",
    "    r\"\\b(i cannot (determine|be certain|provide|diagnose))\\b\"\n",
    ")\n",
    "\n",
    "NORMATIVE = r'\\b(should|ought|must|avoid|fair(ness)?|bias(ed|)?|harm(ful)?)\\b'\n",
    "\n",
    "# Persona cue mentions\n",
    "# Compile with VERBOSE + IGNORECASE for readability/flexibility\n",
    "RXFLAGS = re.IGNORECASE | re.VERBOSE\n",
    "\n",
    "PERSONA_PATTERNS = {\n",
    "    # Knowledge framing personas\n",
    "    \"ignore_world\": re.compile(r\"\"\"\n",
    "        \\b(?:ignore|disregard|exclude)\\s+\n",
    "           (?:world(?:\\s+knowledge)?|external\\s+knowledge|prior\\s+knowledge)\\b\n",
    "    \"\"\", RXFLAGS),\n",
    "    \"embrace_world\": re.compile(r\"\"\"\n",
    "        \\b(?:embrace|use|leverage|incorporate)\\s+\n",
    "           (?:world(?:\\s+knowledge)?|external\\s+knowledge|prior\\s+knowledge)\\b\n",
    "    \"\"\", RXFLAGS),\n",
    "\n",
    "    # Community-context personas (use \"skin tone\" phrasing)\n",
    "    \"community_lighter\": re.compile(r\"\"\"\n",
    "        \\b(?:lighter(?:\\s+skin(?:\\s*tone)?)?|fair(?:er)?(?:\\s+skin(?:\\s*tone)?)?)\\s+\n",
    "           (?:community|group|background|population)\\b\n",
    "    \"\"\", RXFLAGS),\n",
    "    \"community_darker\": re.compile(r\"\"\"\n",
    "        \\b(?:darker(?:\\s+skin(?:\\s*tone)?)?|deep(?:er)?(?:\\s+skin(?:\\s*tone)?)?)\\s+\n",
    "           (?:community|group|background|population)\\b\n",
    "    \"\"\", RXFLAGS),\n",
    "\n",
    "    # Identity-related persona framings (linguistic self-references only)\n",
    "    \"persona_white\": re.compile(r\"\"\"\n",
    "        \\b(?:white|caucasian)\\b\n",
    "        (?:\\s+(?:community|group|background|population|skin\\s*tone))?\n",
    "    \"\"\", RXFLAGS),\n",
    "\n",
    "    \"persona_black\": re.compile(r\"\"\"\n",
    "        \\bblack\\b\n",
    "        (?:\\s+(?:community|group|background|population|skin\\s*tone))?\n",
    "        (?!\\s*and\\s*white)\n",
    "    \"\"\", RXFLAGS),\n",
    "\n",
    "    \"persona_africanamerican\": re.compile(r\"\"\"\n",
    "        \\bafrican[-\\s]?american(?:s)?\\b\n",
    "        (?:\\s+(?:community|group|background|population|skin\\s*tone))?\n",
    "    \"\"\", RXFLAGS),\n",
    "\n",
    "    \"persona_hispanic\": re.compile(r\"\"\"\n",
    "        \\b(?:hispanic|latino|latina|latinx|latine)\\b\n",
    "        (?:\\s+(?:community|group|background|population|skin\\s*tone))?\n",
    "    \"\"\", RXFLAGS),\n",
    "\n",
    "    \"persona_indigenous\": re.compile(r\"\"\"\n",
    "        \\b(?:indigenous|native\\s+(?:american|peoples?)|first\\s+nations?|aboriginal)\\b\n",
    "        (?:\\s+(?:community|group|background|population|skin\\s*tone))?\n",
    "    \"\"\", RXFLAGS),\n",
    "\n",
    "    \"persona_asian\": re.compile(r\"\"\"\n",
    "        \\b(?:asian|east\\s+asian|south\\s+asian|southeast\\s+asian|asian[-\\s]?american)\\b\n",
    "        (?:\\s+(?:community|group|background|population|skin\\s*tone))?\n",
    "    \"\"\", RXFLAGS),\n",
    "\n",
    "    # Colorism / bias-awareness framings\n",
    "    \"persona_colorism\": re.compile(r\"\"\"\n",
    "        \\b(?:colorism|skin\\s*tone\\s*bias|shade\\s*bias|fairness\\s*bias)\\b\n",
    "    \"\"\", RXFLAGS),\n",
    "}\n",
    "\n",
    "\n",
    "def add_theme_flags(df):\n",
    "    txt = df['rationale'].str.lower()\n",
    "    df['has_disclaimer'] = txt.str.contains(DISCLAIMER, regex=True)\n",
    "    df['hedge_count']    = txt.str.count(HEDGES)\n",
    "    df['normative_count']= txt.str.count(NORMATIVE)\n",
    "    # Per-persona counts\n",
    "    composite = 0\n",
    "    for key, rx in PERSONA_PATTERNS.items():\n",
    "        col = f'persona_ref__{key}'\n",
    "        df[col] = txt.str.count(rx)\n",
    "        composite = composite + df[col]\n",
    "\n",
    "    # Back-compatible composite (use this where you previously used persona_refs)\n",
    "    df['persona_refs'] = composite\n",
    "\n",
    "    #df['persona_refs']   = txt.str.count(PERSONA_WORDS)\n",
    "    return df\n",
    "\n",
    "# -------------------------\n",
    "# 3) Sentiment (VADER)\n",
    "# -------------------------\n",
    "_analyzer = SentimentIntensityAnalyzer()\n",
    "def _vader(text): \n",
    "    return _analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "def add_sentiment(df):\n",
    "    df['sentiment'] = df['rationale'].apply(_vader)\n",
    "    return df\n",
    "\n",
    "# -------------------------\n",
    "# 4) Lengths & normalized rates\n",
    "# -------------------------\n",
    "def add_lengths_and_rates(df):\n",
    "    df['n_words'] = df['rationale'].str.split().str.len().fillna(0).astype(int)\n",
    "    # Per-100-word rates (avoid div/0)\n",
    "    denom = df['n_words'].replace(0, pd.NA)\n",
    "    df['hedges_per_100']    = (df['hedge_count']    / denom) * 100\n",
    "    df['normative_per_100'] = (df['normative_count'] / denom) * 100\n",
    "    # Per-persona rates \n",
    "    for key in PERSONA_PATTERNS:\n",
    "        df[f'persona_ref_rate__{key}'] = (df[f'persona_ref__{key}'] / denom) * 100\n",
    "        # composite rate (matches old behavior)\n",
    "    #df['persona_per_100'] = (df['persona_refs'] / denom) * 100\n",
    "    df['persona_per_100']   = (df['persona_refs']    / denom) * 100\n",
    "    return df\n",
    "\n",
    "# -------------------------\n",
    "# 5) Group summaries for Results\n",
    "# -------------------------\n",
    "def summarize_by_group(df):\n",
    "    g = df.groupby(['model','condition'], dropna=False)\n",
    "    out = g.agg(\n",
    "        n=('rationale','count'),\n",
    "        mean_words=('n_words','mean'),\n",
    "        mean_sent=('sentiment','mean'),\n",
    "        pct_disclaimer=('has_disclaimer','mean'),\n",
    "        mean_hedges=('hedge_count','mean'),\n",
    "        mean_normative=('normative_count','mean'),\n",
    "        mean_persona_refs=('persona_refs','mean'),\n",
    "        hedges_per_100=('hedges_per_100','mean'),\n",
    "        normative_per_100=('normative_per_100','mean'),\n",
    "        persona_per_100=('persona_per_100','mean'),\n",
    "    ).reset_index()\n",
    "\n",
    "    # Formatting\n",
    "    out['pct_disclaimer'] = (out['pct_disclaimer']*100).round(1)\n",
    "    for c in ['mean_words','mean_sent','mean_hedges','mean_normative','mean_persona_refs',\n",
    "              'hedges_per_100','normative_per_100','persona_per_100']:\n",
    "        out[c] = out[c].astype(float).round(3)\n",
    "    return out.sort_values(['model','condition']).reset_index(drop=True)\n",
    "\n",
    "# -------------------------\n",
    "# 6) Quote pulls (exemplars)\n",
    "# -------------------------\n",
    "def exemplar_quotes(df, model, condition, k=2, sort_by='hedge_count', largest=True):\n",
    "    \"\"\"\n",
    "    Return up to k exemplar rationales for a given model & condition.\n",
    "    sort_by: 'hedge_count', 'sentiment', 'n_words', or any column you added.\n",
    "    largest=True -> highest values; False -> lowest.\n",
    "    \"\"\"\n",
    "    g = df[(df['model']==model) & (df['condition']==condition)].copy()\n",
    "    if g.empty:\n",
    "        return []\n",
    "    g = g.sort_values(sort_by, ascending=not largest)\n",
    "    # Return short tuples: (image_name, rating, sort_value, rationale_snippet)\n",
    "    exemplars = []\n",
    "    for _, row in g.head(k).iterrows():\n",
    "        snippet = re.sub(r'\\s+', ' ', row['rationale']).strip()\n",
    "        exemplars.append({\n",
    "            'image_name': row['image_name'],\n",
    "            'rating': row['rating'],\n",
    "            sort_by: row[sort_by],\n",
    "            'rationale': snippet\n",
    "        })\n",
    "    return exemplars\n",
    "\n",
    "def exemplar_pair(df, model, condition, k_each=1, sort_by='hedge_count'):\n",
    "    \"\"\"\n",
    "    Get a 'high vs low' pair on a chosen metric for one model/persona.\n",
    "    \"\"\"\n",
    "    hi = exemplar_quotes(df, model, condition, k=k_each, sort_by=sort_by, largest=True)\n",
    "    lo = exemplar_quotes(df, model, condition, k=k_each, sort_by=sort_by, largest=False)\n",
    "    return {'high': hi, 'low': lo}\n",
    "\n",
    "# -------------------------\n",
    "# 7) Typical call sequence\n",
    "# -------------------------\n",
    "df_r = get_rationales(long_df)\n",
    "df_r = add_theme_flags(df_r)\n",
    "df_r = add_sentiment(df_r)\n",
    "df_r = add_lengths_and_rates(df_r)\n",
    "summary_df = summarize_by_group(df_r)\n",
    "print(summary_df.head(60))\n",
    "\n",
    "# Save summary to CSV\n",
    "summary_path = os.path.join(output_path, 'rationale_summary_by_model_condition.csv')\n",
    "summary_df.to_csv(summary_path, index=False)\n",
    "\n",
    "#Example: pull quotes for GPT under 'cultural_darker'\n",
    "ex = exemplar_pair(df_r, model='GPT', condition='cultural_darker', k_each=1, sort_by='hedge_count')\n",
    "print(\"High-hedge example:\", ex['high'])\n",
    "print(\"Low-hedge example:\", ex['low'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b1067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Copy your summary_df first\n",
    "tbl = summary_df.copy()\n",
    "\n",
    "# Optional: nicer y tick labels\n",
    "pretty_map = {\n",
    "    'baseline':'Baseline',\n",
    "    'cultural_africanamerican':'African American',\n",
    "    'cultural_asian':'Asian',\n",
    "    'cultural_black':'Black',\n",
    "    'cultural_colorism':'Colorism',\n",
    "    'cultural_darker':'Darker Community',\n",
    "    'cultural_hispanic':'Hispanic',\n",
    "    'cultural_indigenous':'Indigenous',\n",
    "    'cultural_lighter':'Lighter Community',\n",
    "    'cultural_white':'White',\n",
    "    'embrace_world':'Embrace world knowledge',\n",
    "    'ignore_world':'Ignore world knowledge'\n",
    "}\n",
    "\n",
    "# Fix minor typos / standardize condition names\n",
    "fix = {'cultural_asain':'cultural_asian'}\n",
    "tbl['condition'] = tbl['condition'].replace(fix)\n",
    "\n",
    "# optional: order models/conditions for consistent plots\n",
    "model_order = ['Claude','GPT','Gemini','Llama']\n",
    "cond_order = ['baseline','cultural_africanamerican','cultural_asian','cultural_black',\n",
    "              'cultural_colorism','cultural_darker','cultural_hispanic','cultural_indigenous',\n",
    "              'cultural_lighter','cultural_white','embrace_world','ignore_world']\n",
    "tbl['model'] = pd.Categorical(tbl['model'], categories=model_order, ordered=True)\n",
    "tbl['condition'] = pd.Categorical(tbl['condition'], categories=cond_order, ordered=True)\n",
    "\n",
    "# keep only the metrics you want in the paper (we’ve removed normative language)\n",
    "metrics = ['mean_words', 'hedges_per_100', 'persona_per_100', 'mean_sent'] \n",
    "\n",
    "# weight by n (images per condition) so conditions contribute proportionally\n",
    "w = tbl.assign(w=tbl['n'].clip(lower=1))\n",
    "\n",
    "per_model = (\n",
    "    tbl.assign(\n",
    "        words_w    = tbl['mean_words']      * w['w'],\n",
    "        hedges_w   = tbl['hedges_per_100']  * w['w'],\n",
    "        persona_w  = tbl['persona_per_100'] * w['w'],\n",
    "        sent_w     = tbl['mean_sent']       * w['w']\n",
    "    )\n",
    "    .groupby('model', as_index=False)\n",
    "    .agg(\n",
    "        n_total=('n','sum'),\n",
    "        mean_words=('words_w','sum'),\n",
    "        hedges_per_100=('hedges_w','sum'),\n",
    "        persona_per_100=('persona_w','sum'),\n",
    "        mean_sent=('sent_w','sum'),\n",
    "    )\n",
    ")\n",
    "\n",
    "per_model['mean_words']       = (per_model['mean_words']       / per_model['n_total']).round(2)\n",
    "per_model['hedges_per_100']   = (per_model['hedges_per_100']   / per_model['n_total']).round(3)\n",
    "per_model['persona_per_100']  = (per_model['persona_per_100']  / per_model['n_total']).round(3)\n",
    "per_model['mean_sent']        = (per_model['mean_sent']        / per_model['n_total']).round(3)\n",
    "\n",
    "print(per_model.to_string(index=False))\n",
    "\n",
    "# Export for paper\n",
    "path = os.path.join(output_path, 'per_model_qual_summary.csv')\n",
    "per_model.to_csv(path, index=False)\n",
    "with open('per_model_qual_summary.tex','w') as f:\n",
    "    f.write(per_model.to_latex(index=False, caption='Per-model qualitative rationale summary',\n",
    "                               label='tab:per_model_qual', float_format=\"%.3f\"))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7,5))\n",
    "for m in model_order:\n",
    "    d = tbl[tbl['model']==m]\n",
    "    ax.scatter(d['mean_words'], d['hedges_per_100'],\n",
    "               s=20 + 80*(d['persona_per_100'] / (1 + d['persona_per_100']).clip(upper=3)),\n",
    "               label=m, alpha=0.9)\n",
    "\n",
    "ax.set_xlabel('Rationale length (mean words)')\n",
    "ax.set_ylabel('Hedges per 100 words')\n",
    "ax.set_title('Rationale style by model and condition')\n",
    "ax.legend(title='Model', frameon=False)\n",
    "ax.grid(True, alpha=0.2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_path + 'style_scatter_length_vs_hedges.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "paper_table = per_model[['model','mean_words','hedges_per_100','persona_per_100','mean_sent']].copy()\n",
    "paper_table.columns = ['Model','Mean words','Hedges/100','Persona refs/100','Mean sentiment']\n",
    "print(paper_table.to_string(index=False))\n",
    "\n",
    "paper_table.to_csv('paper_table_qualitative_summary.csv', index=False)\n",
    "with open('paper_table_qualitative_summary.tex','w') as f:\n",
    "    f.write(paper_table.to_latex(index=False, caption='Qualitative rationale metrics by model',\n",
    "                                 label='tab:qual_model_summary', float_format=\"%.3f\"))\n",
    "    \n",
    "def lollipop_axis(ax, d, metric, title):\n",
    "    d = d.sort_values('condition')\n",
    "    y = np.arange(len(d))\n",
    "    ax.hlines(y, 0, d[metric], linewidth=1)\n",
    "    ax.plot(d[metric], y, 'o')\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels([pretty_map.get(c, str(c)) for c in d['condition']])\n",
    "    ax.set_xlabel(metric.replace('_',' '))\n",
    "    ax.set_title(title, weight='bold')\n",
    "    ax.grid(True, axis='x', alpha=0.2)\n",
    "\n",
    "metric = 'hedges_per_100'\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Determine a common x-limit across all models for comparability\n",
    "xmin = 0\n",
    "xmax = float(tbl[metric].max()) * 1.1  # small headroom\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    d = tbl[tbl['model']==m]\n",
    "    lollipop_axis(axes[i], d, metric, f'Hedges/100 — {m}')\n",
    "    axes[i].set_xlim(xmin, xmax)\n",
    "\n",
    "# Panel labels A–D (optional)\n",
    "panel_labels = ['A','B','C','D']\n",
    "for ax, lab in zip(axes, panel_labels):\n",
    "    ax.text(0.01, 1.1, lab, transform=ax.transAxes, va='top', ha='left', fontsize=12, weight='bold')\n",
    "\n",
    "fig.suptitle('Hedging by persona (lollipop plots per model)', y=0.995, weight='bold')\n",
    "fig.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.savefig('figure_hedges_all_models.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "metric = 'persona_per_100'\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "xmin = 0\n",
    "xmax = float(tbl[metric].max()) * 1.1  # common x-limit\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    d = tbl[tbl['model']==m]\n",
    "    lollipop_axis(axes[i], d, metric, f'Persona refs/100 — {m}')\n",
    "    axes[i].set_xlim(xmin, xmax)\n",
    "\n",
    "panel_labels = ['A','B','C','D']\n",
    "for ax, lab in zip(axes, panel_labels):\n",
    "    ax.text(0.01, 1.1, lab, transform=ax.transAxes, va='top', ha='left', fontsize=12, weight='bold')\n",
    "\n",
    "fig.suptitle('References to identity constructs for each prompt', y=0.995, weight='bold')\n",
    "fig.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.savefig('figure_persona_refs_all_models.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- Sentiment lollipop plots by model/persona (VADER compound) ---\n",
    "\n",
    "metric = 'mean_sent'  # already in summary_df as produced earlier\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "# VADER compound ranges from -1 to 1. Keep a symmetric axis for comparability.\n",
    "xmin, xmax = -1.0, 1.0\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    d = tbl[tbl['model'] == m].copy()\n",
    "    # Safety: ensure numeric\n",
    "    d[metric] = pd.to_numeric(d[metric], errors='coerce')\n",
    "    lollipop_axis(axes[i], d, metric, f'{m}')\n",
    "    axes[i].set_xlim(xmin, xmax)\n",
    "    # Zero-line for polarity neutrality\n",
    "    axes[i].axvline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "    # Add x-axis label\n",
    "    axes[i].set_xlabel('VADER compound sentiment score')\n",
    "\n",
    "# Panel labels A–D\n",
    "panel_labels = ['A','B','C','D']\n",
    "for ax, lab in zip(axes, panel_labels):\n",
    "    ax.text(0.01, 1.1, lab, transform=ax.transAxes, va='top', ha='left', fontsize=12, weight='bold')\n",
    "\n",
    "fig.suptitle('Valence (VADER) by persona for each model', y=0.995, weight='bold')\n",
    "fig.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.savefig(os.path.join(output_path, 'figure_valence_all_models.png'), dpi=300)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2681bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- add colors for models ---\n",
    "model_colors = {\n",
    "    'GPT': '#2ecc71',    # Green\n",
    "    'Claude': '#e74c3c', # Red\n",
    "    'Llama': '#3498db',  # Blue\n",
    "    'Gemini': '#f1c40f', # Yellow\n",
    "}\n",
    "# fallback palette if extra models exist\n",
    "default_palette = ['#8e44ad', '#16a085', '#d35400', '#2c3e50', '#7f8c8d']\n",
    "from itertools import cycle\n",
    "_default_cycle = cycle(default_palette)\n",
    "\n",
    "models_present = [m for m in model_order if m in tbl['model'].unique()]\n",
    "model_to_color = {}\n",
    "for m in models_present:\n",
    "    # try exact family match, else fallback to cycle\n",
    "    family = next((f for f in model_colors if f.lower() in str(m).lower()), None)\n",
    "    model_to_color[m] = model_colors.get(family, next(_default_cycle))\n",
    "\n",
    "# Modified lollipop_axis to take color\n",
    "def lollipop_axis(ax, d, metric, title, color='#333333'):\n",
    "    d = d.sort_values('condition')\n",
    "    y = np.arange(len(d))\n",
    "    # horizontal lollipop stems\n",
    "    ax.hlines(y, 0, d[metric], linewidth=1.5, color=color, alpha=0.9)\n",
    "    # points: filled circle with thin black edge for legibility\n",
    "    ax.plot(d[metric], y, 'o', markersize=7, markerfacecolor=color, markeredgecolor='k', markeredgewidth=0.4)\n",
    "    ax.set_yticks(y)\n",
    "    ax.set_yticklabels([pretty_map.get(c, str(c)) for c in d['condition']])\n",
    "    ax.set_xlabel(metric.replace('_',' '))\n",
    "    ax.set_title(title, weight='bold')\n",
    "    ax.grid(True, axis='x', alpha=0.2)\n",
    "\n",
    "# Common variables used in three blocks\n",
    "metric = 'hedges_per_100'\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Determine a common x-limit across all models for comparability\n",
    "xmin = 0\n",
    "xmax = float(tbl[metric].max()) * 1.1  # small headroom\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    d = tbl[tbl['model']==m]\n",
    "    color = model_to_color.get(m, '#444444')\n",
    "    lollipop_axis(axes[i], d, metric, f'Hedges/100 — {m}', color=color)\n",
    "    axes[i].set_xlim(xmin, xmax)\n",
    "\n",
    "# Panel labels A–D (optional)\n",
    "panel_labels = ['A','B','C','D']\n",
    "for ax, lab in zip(axes, panel_labels):\n",
    "    ax.text(0.01, 1.1, lab, transform=ax.transAxes, va='top', ha='left', fontsize=12, weight='bold')\n",
    "\n",
    "fig.suptitle('Hedging by persona (lollipop plots per model)', y=0.995, weight='bold')\n",
    "fig.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.savefig('figure_hedges_all_models_colored.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- Persona refs per 100 ---\n",
    "metric = 'persona_per_100'\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "xmin = 0\n",
    "xmax = float(tbl[metric].max()) * 1.1  # common x-limit\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    d = tbl[tbl['model']==m]\n",
    "    color = model_to_color.get(m, '#444444')\n",
    "    lollipop_axis(axes[i], d, metric, f'Persona refs/100 — {m}', color=color)\n",
    "    axes[i].set_xlim(xmin, xmax)\n",
    "\n",
    "panel_labels = ['A','B','C','D']\n",
    "for ax, lab in zip(axes, panel_labels):\n",
    "    ax.text(0.01, 1.1, lab, transform=ax.transAxes, va='top', ha='left', fontsize=12, weight='bold')\n",
    "\n",
    "fig.suptitle('References to identity constructs for each prompt', y=0.995, weight='bold')\n",
    "fig.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.savefig('figure_persona_refs_all_models_colored.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# --- Sentiment lollipop plots by model/persona (VADER compound) ---\n",
    "metric = 'mean_sent'  # already in summary_df as produced earlier\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "# VADER compound ranges from -1 to 1. Keep a symmetric axis for comparability.\n",
    "xmin, xmax = -1.0, 1.0\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    d = tbl[tbl['model'] == m].copy()\n",
    "    # Safety: ensure numeric\n",
    "    d[metric] = pd.to_numeric(d[metric], errors='coerce')\n",
    "    color = model_to_color.get(m, '#444444')\n",
    "    lollipop_axis(axes[i], d, metric, f'{m}', color=color)\n",
    "    axes[i].set_xlim(xmin, xmax)\n",
    "    # Zero-line for polarity neutrality\n",
    "    axes[i].axvline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "    # Add x-axis label\n",
    "    axes[i].set_xlabel('VADER compound sentiment score')\n",
    "\n",
    "# Panel labels A–D\n",
    "panel_labels = ['A','B','C','D']\n",
    "for ax, lab in zip(axes, panel_labels):\n",
    "    ax.text(0.01, 1.1, lab, transform=ax.transAxes, va='top', ha='left', fontsize=12, weight='bold')\n",
    "\n",
    "fig.suptitle('Valence (VADER) by persona for each model', y=0.995, weight='bold')\n",
    "fig.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.savefig(os.path.join(output_path, 'figure_valence_all_models_colored.png'), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# ---------- 1) Compute within-model tests vs baseline ----------\n",
    "def stars_from_p(p):\n",
    "    if pd.isna(p):\n",
    "        return \"\"\n",
    "    return \"****\" if p < 1e-4 else (\"***\" if p < 1e-3 else (\"**\" if p < 1e-2 else (\"*\" if p < 0.05 else \"\")))\n",
    "\n",
    "def sentiment_tests_vs_baseline(df_r, model_order, baseline=\"baseline\"):\n",
    "    \"\"\"\n",
    "    df_r must have columns: model, condition, sentiment\n",
    "    Returns dict: star_map[model][condition] = '***' ('' for baseline or ns)\n",
    "    \"\"\"\n",
    "    star_map = {m: {} for m in model_order}\n",
    "    for m in model_order:\n",
    "        d = df_r[df_r['model'] == m].copy()\n",
    "        # Per-rationale sentiment vectors\n",
    "        base = d[d['condition'] == baseline]['sentiment'].dropna().values\n",
    "        if base.size == 0:\n",
    "            # No baseline data; skip stars for this model\n",
    "            continue\n",
    "\n",
    "        # Gather p-values for all non-baseline conditions\n",
    "        conds = sorted(c for c in d['condition'].unique() if c != baseline)\n",
    "        pvals = []\n",
    "        kept_conds = []\n",
    "        for c in conds:\n",
    "            x = d[d['condition'] == c]['sentiment'].dropna().values\n",
    "            if x.size == 0:\n",
    "                pvals.append(np.nan); kept_conds.append(c); continue\n",
    "            # Welch t-test (unequal variances)\n",
    "            t, p = stats.ttest_ind(x, base, equal_var=False, nan_policy='omit')\n",
    "            pvals.append(p); kept_conds.append(c)\n",
    "\n",
    "        # Holm adjust within model\n",
    "        pvals_arr = np.array([np.nan if pd.isna(p) else p for p in pvals], dtype=float)\n",
    "        # mask nans for adjustment\n",
    "        valid_mask = ~np.isnan(pvals_arr)\n",
    "        adj = np.full_like(pvals_arr, np.nan)\n",
    "        if valid_mask.sum() > 0:\n",
    "            _, p_adj, _, _ = multipletests(pvals_arr[valid_mask], method='holm')\n",
    "            adj[valid_mask] = p_adj\n",
    "\n",
    "        # Fill stars\n",
    "        for c, p_adj in zip(kept_conds, adj):\n",
    "            star_map[m][c] = stars_from_p(p_adj)\n",
    "        # Baseline never has a star\n",
    "        star_map[m][baseline] = \"\"\n",
    "    return star_map\n",
    "\n",
    "# Build star map from your per-rationale DF\n",
    "# df_r came from your earlier pipeline (get_rationales -> add_theme_flags -> add_sentiment, etc.)\n",
    "star_map = sentiment_tests_vs_baseline(df_r, model_order, baseline=\"baseline\")\n",
    "\n",
    "# ---------- 2) Plot sentiment lollipop + stars ----------\n",
    "metric = 'mean_sent'\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "axes = axes.ravel()\n",
    "xmin, xmax = -1.0, 1.0  # VADER compound range; keep symmetric\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    d = tbl[tbl['model'] == m].copy()  # persona-level means from your summary\n",
    "    d[metric] = pd.to_numeric(d[metric], errors='coerce')\n",
    "    lollipop_axis(axes[i], d, metric, f'Sentiment (VADER) — {m}')\n",
    "    axes[i].set_xlim(xmin, xmax)\n",
    "    axes[i].axvline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "\n",
    "    # --- annotate stars next to each persona (except baseline) ---\n",
    "    # Recreate the y positions used inside lollipop_axis\n",
    "    d = d.sort_values('condition')\n",
    "    y = np.arange(len(d))\n",
    "    # small horizontal offset for the star placement\n",
    "    xpad = 0.02 * (xmax - xmin)\n",
    "\n",
    "    for yy, (_, row) in zip(y, d.iterrows()):\n",
    "        cond = row['condition']\n",
    "        if cond == 'baseline':\n",
    "            continue\n",
    "        xval = row[metric]\n",
    "        star = star_map.get(m, {}).get(cond, \"\")\n",
    "        if not star:\n",
    "            continue\n",
    "        # If near the right edge, place stars to the left\n",
    "        if pd.notna(xval):\n",
    "            xp = xval + xpad if (xval + xpad) < (xmax - 0.02) else xval - xpad\n",
    "            ha = 'left' if xp >= xval else 'right'\n",
    "            axes[i].text(xp, yy, star, va='center', ha=ha, fontsize=11, weight='bold')\n",
    "\n",
    "# Panel labels\n",
    "for ax, lab in zip(axes, ['A','B','C','D']):\n",
    "    ax.text(0.01, 1.1, lab, transform=ax.transAxes, va='top', ha='left', fontsize=12, weight='bold')\n",
    "\n",
    "fig.suptitle('Sentiment by persona with significance vs baseline (Holm-adjusted)', y=0.995, weight='bold')\n",
    "fig.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.savefig(os.path.join(output_path, 'figure_sentiment_all_models_with_stars.png'), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19645202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "df_r = get_rationales(long_df)\n",
    "df_r = add_sentiment(df_r)\n",
    "\n",
    "def stars_from_p(p):\n",
    "    if pd.isna(p):\n",
    "        return \"\"\n",
    "    return \"****\" if p < 1e-4 else (\"***\" if p < 1e-3 else (\"**\" if p < 1e-2 else (\"*\" if p < 0.05 else \"\")))\n",
    "\n",
    "def sentiment_tests_vs_baseline(df_r, model_order, baseline=\"baseline\"):\n",
    "    star_map = {m: {} for m in model_order}\n",
    "    results = []\n",
    "    for m in model_order:\n",
    "        d = df_r[df_r['model'] == m].copy()\n",
    "        base = d[d['condition'] == baseline]['sentiment'].dropna().values\n",
    "        if base.size == 0:\n",
    "            continue\n",
    "        conds = sorted(c for c in d['condition'].unique() if c != baseline)\n",
    "        pvals = []\n",
    "        kept_conds = []\n",
    "        for c in conds:\n",
    "            x = d[d['condition'] == c]['sentiment'].dropna().values\n",
    "            if x.size == 0:\n",
    "                pvals.append(np.nan); kept_conds.append(c); continue\n",
    "            t, p = stats.ttest_ind(x, base, equal_var=False, nan_policy='omit')\n",
    "            pvals.append(p); kept_conds.append(c)\n",
    "        pvals_arr = np.array([np.nan if pd.isna(p) else p for p in pvals], dtype=float)\n",
    "        valid_mask = ~np.isnan(pvals_arr)\n",
    "        adj = np.full_like(pvals_arr, np.nan)\n",
    "        if valid_mask.sum() > 0:\n",
    "            _, p_adj, _, _ = multipletests(pvals_arr[valid_mask], method='holm')\n",
    "            adj[valid_mask] = p_adj\n",
    "        for c, raw, padj in zip(kept_conds, pvals, adj):\n",
    "            star = stars_from_p(padj)\n",
    "            star_map[m][c] = star\n",
    "            results.append({\n",
    "                \"model\": m,\n",
    "                \"condition\": c,\n",
    "                \"p_raw\": raw,\n",
    "                \"p_adj\": padj,\n",
    "                \"stars\": star\n",
    "            })\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "model_order = ['Claude','GPT','Gemini','Llama']\n",
    "results_df = sentiment_tests_vs_baseline(df_r, model_order)\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32681a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Normalize spelling in BOTH dataframes\n",
    "fix = {'cultural_asain': 'cultural_asian'}\n",
    "results_df['condition'] = results_df['condition'].replace(fix)\n",
    "tbl['condition']        = tbl['condition'].replace(fix)\n",
    "\n",
    "# 1) Keep only significant results and build the lookup\n",
    "sig_results = results_df[results_df['p_adj'] < 0.05].copy()\n",
    "star_map = { (row['model'], row['condition']) : row['stars']\n",
    "             for _, row in sig_results.iterrows() }\n",
    "\n",
    "print(\"Significant (model, condition) pairs:\", list(star_map.keys()))\n",
    "# You should see: [('Claude','cultural_asian')] based on your table\n",
    "\n",
    "# 2) Plot with correct condition lookup + robust y positions\n",
    "metric = 'mean_sent'\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "axes = axes.ravel()\n",
    "xmin, xmax = -1.0, 1.0  # symmetric for VADER\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    d = tbl[tbl['model'] == m].copy()\n",
    "    d = d.sort_values('condition')                # match lollipop_axis y-order\n",
    "    d[metric] = pd.to_numeric(d[metric], errors='coerce')\n",
    "\n",
    "    # draw the lollipop panel\n",
    "    lollipop_axis(axes[i], d, metric, f'Sentiment (VADER) — {m}')\n",
    "    axes[i].set_xlim(xmin, xmax)\n",
    "    axes[i].axvline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "\n",
    "    # exact y positions used by lollipop_axis\n",
    "    y_positions = np.arange(len(d))\n",
    "    # small horizontal offset so stars don't overlap the dot\n",
    "    xpad = 0.04 * (xmax - xmin)\n",
    "\n",
    "    # annotate using the ACTUAL condition string from the row\n",
    "    for yy, (_, row) in enumerate(d.iterrows()):\n",
    "        cond = row['condition']\n",
    "        xval = row[metric]\n",
    "        star = star_map.get((m, cond), \"\")\n",
    "        if star and pd.notna(xval):\n",
    "            # place star to right; if near right edge, flip to left\n",
    "            xp  = xval + xpad if (xval + xpad) < (xmax - 0.02) else xval - xpad\n",
    "            hal = 'left' if xp >= xval else 'right'\n",
    "            axes[i].text(xp, yy, star,\n",
    "                         va='center', ha=hal,\n",
    "                         fontsize=14, weight='bold',\n",
    "                         color='black', zorder=10)\n",
    "\n",
    "# panel labels\n",
    "for ax, lab in zip(axes, ['A','B','C','D']):\n",
    "    ax.text(0.01, 1.1, lab, transform=ax.transAxes,\n",
    "            va='top', ha='left', fontsize=12, weight='bold')\n",
    "\n",
    "fig.suptitle('Sentiment by persona with significance vs baseline (Holm-adjusted)',\n",
    "             y=0.995, weight='bold')\n",
    "fig.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.savefig(os.path.join(output_path, 'figure_sentiment_all_models_with_stars.png'), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444ebc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hedging significance tests vs baseline\n",
    "df_r = get_rationales(long_df)\n",
    "df_r = add_theme_flags(df_r)  # need hedge_count\n",
    "df_r = add_lengths_and_rates(df_r)  # need hedges_per_100\n",
    "\n",
    "def stars_from_p(p):\n",
    "    if pd.isna(p):\n",
    "        return \"\"\n",
    "    return \"****\" if p < 1e-4 else (\"***\" if p < 1e-3 else (\"**\" if p < 1e-2 else (\"*\" if p < 0.05 else \"\")))\n",
    "\n",
    "def hedging_tests_vs_baseline(df_rr, model_order, baseline='baseline', min_n=5):\n",
    "    \"\"\"\n",
    "    Welch t-tests comparing hedges_per_100 between each persona and baseline within each model.\n",
    "    Holm correction is applied across personas per model.\n",
    "    min_n: require at least this many rationales per group to test; else p=nan.\n",
    "    Returns: results_df and star_map usable for plotting.\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    star_map = {m: {} for m in model_order}\n",
    "    for m in model_order:\n",
    "        d = df_rr[(df_rr['model'] == m)].copy()\n",
    "        base = d[d['condition'] == baseline]['hedges_per_100'].dropna()\n",
    "        if base.shape[0] < min_n:\n",
    "            continue\n",
    "        conds = [c for c in d['condition'].dropna().unique() if c != baseline]\n",
    "        pvals, kept = [], []\n",
    "        for c in conds:\n",
    "            x = d[d['condition'] == c]['hedges_per_100'].dropna()\n",
    "            if x.shape[0] < min_n:\n",
    "                pvals.append(np.nan); kept.append(c); continue\n",
    "            t, p = stats.ttest_ind(x, base, equal_var=False, nan_policy='omit')\n",
    "            pvals.append(p); kept.append(c)\n",
    "        pvals = np.array(pvals, dtype=float)\n",
    "        mask = ~np.isnan(pvals)\n",
    "        p_adj = np.full_like(pvals, np.nan)\n",
    "        if mask.sum() > 0:\n",
    "            _, p_adj[mask], _, _ = multipletests(pvals[mask], method='holm')\n",
    "        for c, p_raw, p_a in zip(kept, pvals, p_adj):\n",
    "            out.append({\"model\": m, \"condition\": c, \"p_raw\": p_raw, \"p_adj\": p_a, \"stars\": stars_from_p(p_a)})\n",
    "            star_map[m][c] = stars_from_p(p_a)\n",
    "        star_map[m][baseline] = \"\"\n",
    "    results_df = pd.DataFrame(out).sort_values(['model','condition']).reset_index(drop=True)\n",
    "    return results_df, star_map\n",
    "\n",
    "# Run tests\n",
    "model_order = ['Claude','GPT','Gemini','Llama']\n",
    "hedge_results_df, hedge_star_map_by_model = hedging_tests_vs_baseline(df_r, model_order, baseline='baseline', min_n=5)\n",
    "\n",
    "# (Optional) quick look\n",
    "print(hedge_results_df.to_string(index=False))\n",
    "\n",
    "# Keep plotting DF in sync with typo fix and build a flat star lookup\n",
    "tbl['condition'] = tbl['condition'].replace(fix)\n",
    "\n",
    "# Flatten star map for convenient lookup\n",
    "hedge_star_map = {(m, c): s for m, d in hedge_star_map_by_model.items() for c, s in d.items()}\n",
    "\n",
    "metric = 'hedges_per_100'\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 7), sharex=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "xmin = 0\n",
    "xmax = float(tbl[metric].max()) * 1.1 if np.isfinite(tbl[metric].max()) else 1.0\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    d = tbl[tbl['model'] == m].copy().sort_values('condition')\n",
    "    lollipop_axis(axes[i], d, metric, f'Hedges/100 — {m}')\n",
    "    axes[i].set_xlim(xmin, xmax)\n",
    "\n",
    "    # annotate stars next to points\n",
    "    y_positions = np.arange(len(d))\n",
    "    xpad = 0.02 * (xmax - xmin) if (xmax - xmin) > 0 else 0.05\n",
    "    for yy, (_, row) in enumerate(d.iterrows()):\n",
    "        cond = row['condition']\n",
    "        xval = row[metric]\n",
    "        star = hedge_star_map.get((m, cond), \"\")\n",
    "        if star and pd.notna(xval):\n",
    "            xp  = xval + xpad if (xval + xpad) < (xmax - 0.02) else xval - xpad\n",
    "            hal = 'left' if xp >= xval else 'right'\n",
    "            axes[i].text(xp, yy, star, va='center', ha=hal,\n",
    "                         fontsize=14, weight='bold', color='black', zorder=10)\n",
    "\n",
    "# panel labels\n",
    "for ax, lab in zip(axes, ['A','B','C','D']):\n",
    "    ax.text(0.01, 1.1, lab, transform=ax.transAxes, va='top', ha='left', fontsize=12, weight='bold')\n",
    "\n",
    "fig.suptitle('Hedging by persona with significance vs baseline (Holm-adjusted)', y=0.995, weight='bold')\n",
    "fig.tight_layout(rect=[0,0,1,0.96])\n",
    "plt.savefig(os.path.join(output_path, 'figure_hedges_all_models_with_stars.png'), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402e20e7",
   "metadata": {},
   "source": [
    "## Combinging Quant and Qual Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747c7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy import stats\n",
    "SHORT = {\n",
    "    'baseline':'BL', 'ignore_world':'IW', 'embrace_world':'EW',\n",
    "    'cultural_white':'WH', 'cultural_black':'BK', 'cultural_asian':'AS',\n",
    "    'cultural_hispanic':'HI', 'cultural_indigenous':'IN',\n",
    "    'cultural_africanamerican':'AA', 'cultural_colorism':'CL',\n",
    "    'cultural_lighter':'LG', 'cultural_darker':'DK'\n",
    "}\n",
    "import matplotlib.patheffects as pe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def annotate_points(ax, d, xcol='delta_emm', ycol='delta_hedges',\n",
    "                    label_col='condition', emm_star_col='emm_stars',\n",
    "                    hedges_sig_lookup=None, topk=3):\n",
    "    \"\"\"\n",
    "    Labels significant points; if none, labels top-K by |x|+|y|.\n",
    "    hedges_sig_lookup: dict {(model, condition) -> stars or ''}.\n",
    "    \"\"\"\n",
    "    # which are \"significant\" by either channel?\n",
    "    sig_mask = d[emm_star_col].astype(str).str.len().gt(0)\n",
    "    if hedges_sig_lookup is not None:\n",
    "        sig_mask = sig_mask | d.apply(lambda r: bool(hedges_sig_lookup.get((str(r['model']), str(r['condition'])), \"\")), axis=1)\n",
    "\n",
    "    lab_df = d[sig_mask].copy()\n",
    "    if lab_df.empty:\n",
    "        # fall back to top-K biggest shifts\n",
    "        d2 = d.assign(mag=(d[xcol].abs() + d[ycol].abs()))\n",
    "        lab_df = d2.sort_values('mag', ascending=False).head(topk)\n",
    "\n",
    "    # simple de-overlap: jitter labels that sit too close\n",
    "    used = []\n",
    "    for _, row in lab_df.iterrows():\n",
    "        x, y = row[xcol], row[ycol]\n",
    "        # offset label a bit away from origin to reduce dot overlap\n",
    "        dx = 0.02 * (np.sign(x) if x != 0 else 1)\n",
    "        dy = 0.02 * (np.sign(y) if y != 0 else 1)\n",
    "        tx, ty = x + dx, y + dy\n",
    "\n",
    "        # nudge if colliding with previous labels\n",
    "        for _ in range(10):\n",
    "            if any(abs(tx-ux) < 0.03 and abs(ty-uy) < 0.03 for (ux, uy) in used):\n",
    "                tx += 0.02\n",
    "                ty += 0.02\n",
    "            else:\n",
    "                break\n",
    "        used.append((tx, ty))\n",
    "\n",
    "        lab = SHORT.get(str(row[label_col]), str(row[label_col]))\n",
    "        ax.text(tx, ty, lab,\n",
    "                ha='left', va='center', fontsize=9, weight='bold',\n",
    "                path_effects=[pe.withStroke(linewidth=3, foreground='white')])\n",
    "\n",
    "        # thin leader line from label to point\n",
    "        ax.plot([x, tx], [y, ty], linewidth=0.6, alpha=0.6)\n",
    "\n",
    "    # legend key for abbreviations (optional: include in caption instead)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "emm_path = \"outputs/cross_model_emms.csv\"  # <-- set this to your file path\n",
    "emm = pd.read_csv(emm_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Standardize condition keys\n",
    "# -----------------------------\n",
    "fix = {'cultural_asain': 'cultural_asian'}\n",
    "for d in (emm, summary_df):\n",
    "    d['condition'] = d['condition'].replace(fix)\n",
    "\n",
    "model_order = ['Claude','GPT','Gemini','Llama']\n",
    "cond_order = ['baseline','cultural_africanamerican','cultural_asian','cultural_black',\n",
    "              'cultural_colorism','cultural_darker','cultural_hispanic','cultural_indigenous',\n",
    "              'cultural_lighter','cultural_white','embrace_world','ignore_world']\n",
    "\n",
    "# -----------------------------\n",
    "# 2) ΔEMM vs baseline within model\n",
    "#    (uses SE combination as an approximation if you don't have contrast SEs)\n",
    "# -----------------------------\n",
    "# Baseline per model\n",
    "base_emm = emm[emm['condition']=='baseline'].set_index('model')[['emmean','SE']].rename(\n",
    "    columns={'emmean':'base_emm','SE':'base_SE'}\n",
    ")\n",
    "\n",
    "emm2 = emm.merge(base_emm, left_on='model', right_index=True, how='left')\n",
    "emm2['delta_emm'] = emm2['emmean'] - emm2['base_emm']\n",
    "\n",
    "# Approx SE for the difference (assumes independence; conservative if cov>0)\n",
    "emm2['SE_delta'] = np.sqrt(emm2['SE']**2 + emm2['base_SE']**2)\n",
    "\n",
    "# 95% CI\n",
    "zcrit = stats.norm.ppf(0.975)\n",
    "emm2['delta_emm_lo'] = emm2['delta_emm'] - zcrit*emm2['SE_delta']\n",
    "emm2['delta_emm_hi'] = emm2['delta_emm'] + zcrit*emm2['SE_delta']\n",
    "\n",
    "# Per-model Holm-adjusted p-values vs baseline (two-sided z-tests)\n",
    "def holm_stars(group):\n",
    "    # exclude baseline itself\n",
    "    g = group[group['condition']!='baseline'].copy()\n",
    "    # some rows could have SE_delta == 0 if degenerate; guard:\n",
    "    g['z'] = g['delta_emm'] / g['SE_delta'].replace(0, np.nan)\n",
    "    g['p_raw'] = 2*(1-stats.norm.cdf(np.abs(g['z'])))\n",
    "    if g['p_raw'].notna().any():\n",
    "        mask = g['p_raw'].notna().values\n",
    "        p_adj = np.full(len(g), np.nan)\n",
    "        p_adj[mask] = multipletests(g.loc[mask, 'p_raw'], method='holm')[1]\n",
    "        g['p_adj'] = p_adj\n",
    "    else:\n",
    "        g['p_adj'] = np.nan\n",
    "    # star mapping\n",
    "    def stars(p):\n",
    "        if pd.isna(p): return \"\"\n",
    "        return \"****\" if p < 1e-4 else (\"***\" if p < 1e-3 else (\"**\" if p < 1e-2 else (\"*\" if p < 0.05 else \"\")))\n",
    "    g['emm_stars'] = g['p_adj'].apply(stars)\n",
    "    return g[['model','condition','delta_emm','delta_emm_lo','delta_emm_hi','SE_delta','p_adj','emm_stars']]\n",
    "\n",
    "emm_delta = (emm2.groupby('model', group_keys=False).apply(holm_stars)\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "# Include baseline row (Δ=0, no stars) so plotting can show all personas aligned\n",
    "baseline_rows = emm2[emm2['condition']=='baseline'][['model','condition']].copy()\n",
    "baseline_rows['delta_emm'] = 0.0\n",
    "baseline_rows['delta_emm_lo'] = 0.0\n",
    "baseline_rows['delta_emm_hi'] = 0.0\n",
    "baseline_rows['SE_delta'] = np.nan\n",
    "baseline_rows['p_adj'] = np.nan\n",
    "baseline_rows['emm_stars'] = \"\"\n",
    "\n",
    "emm_delta = pd.concat([emm_delta, baseline_rows], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) ΔHedges/100 vs baseline within model\n",
    "# -----------------------------\n",
    "tbl = summary_df.copy()\n",
    "base_h = tbl[tbl['condition']=='baseline'][['model','hedges_per_100']].rename(columns={'hedges_per_100':'base_h'})\n",
    "tbl = tbl.merge(base_h, on='model', how='left')\n",
    "tbl['delta_hedges'] = tbl['hedges_per_100'] - tbl['base_h']\n",
    "\n",
    "# Optional: pull Holm-adjusted significance for hedges (if you have hedge_results_df)\n",
    "# fallback: no hedges stars if not available\n",
    "hedges_sig = {}\n",
    "try:\n",
    "    # Expect columns: model, condition, p_adj\n",
    "    tmp = hedge_results_df.copy()\n",
    "    tmp['condition'] = tmp['condition'].replace(fix)\n",
    "    tmp['hedge_stars'] = tmp['p_adj'].apply(lambda p:\n",
    "        (\"****\" if p < 1e-4 else (\"***\" if p < 1e-3 else (\"**\" if p < 1e-2 else (\"*\" if p < 0.05 else \"\")))) if pd.notna(p) else \"\"\n",
    "    )\n",
    "    hedges_sig = {(r.model, r.condition): r.hedge_stars for r in tmp.itertuples(index=False)}\n",
    "except NameError:\n",
    "    # silently proceed without hedges stars\n",
    "    pass\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Merge Δ–Δ and add size/channel\n",
    "# -----------------------------\n",
    "dd = (tbl[['model','condition','delta_hedges','persona_per_100']]\n",
    "      .merge(emm_delta, on=['model','condition'], how='inner'))\n",
    "\n",
    "# Ensure consistent ordering & dtypes\n",
    "dd['model'] = pd.Categorical(dd['model'], categories=model_order, ordered=True)\n",
    "dd['condition'] = pd.Categorical(dd['condition'], categories=cond_order, ordered=True)\n",
    "dd = dd.sort_values(['model','condition'])\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Plot Δ–Δ bivariate by model (2×2 facets)\n",
    "# -----------------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 9), sharex=True, sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Axis limits with some headroom\n",
    "xpad = 0.05 * np.nanmax(np.abs(dd['delta_emm'].values)) if np.isfinite(np.nanmax(np.abs(dd['delta_emm'].values))) else 0.2\n",
    "ypad = 0.05 * np.nanmax(np.abs(dd['delta_hedges'].values)) if np.isfinite(np.nanmax(np.abs(dd['delta_hedges'].values))) else 0.2\n",
    "xmax = np.nanmax(np.abs(dd['delta_emm'].values)) + xpad\n",
    "ymax = np.nanmax(np.abs(dd['delta_hedges'].values)) + ypad\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    ax = axes[i]\n",
    "    d = dd[dd['model']==m].copy()\n",
    "\n",
    "    # zero lines\n",
    "    ax.axvline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "    ax.axhline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "\n",
    "    # scatter points\n",
    "    sizes = 25 + 60 * (d['persona_per_100'].fillna(0) / (1 + d['persona_per_100'].fillna(0))).clip(upper=3)\n",
    "    pts = ax.scatter(d['delta_emm'], d['delta_hedges'], s=sizes)\n",
    "\n",
    "    # horizontal error bars for ΔEMM (95% CI)\n",
    "    ax.errorbar(d['delta_emm'], d['delta_hedges'],\n",
    "                xerr=[d['delta_emm'] - d['delta_emm_lo'], d['delta_emm_hi'] - d['delta_emm']],\n",
    "                fmt='none', linewidth=1, alpha=0.7, capsize=2)\n",
    "\n",
    "    # star for EMM significance\n",
    "    for x, y, star in zip(d['delta_emm'], d['delta_hedges'], d['emm_stars']):\n",
    "        if isinstance(star, str) and star != \"\":\n",
    "            ax.text(x, y + 0.02*ymax, star, ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "    # bold outline for hedges significance\n",
    "    for (x, y, cond) in zip(d['delta_emm'], d['delta_hedges'], d['condition'].astype(str)):\n",
    "        star = hedges_sig.get((m, cond), \"\")\n",
    "        if star != \"\":\n",
    "            ax.scatter([x], [y], s= sizes.iloc[0] if np.ndim(sizes)==0 else 0, facecolors='none', linewidths=2)\n",
    "\n",
    "    # label a few key personas to aid reading (optional)\n",
    "    annotate_points(\n",
    "    ax, d,\n",
    "    xcol='delta_emm', ycol='delta_hedges',\n",
    "    label_col='condition',\n",
    "    emm_star_col='emm_stars',\n",
    "    hedges_sig_lookup=hedges_sig  # your {(model, condition): stars} dict or None\n",
    ")\n",
    "\n",
    "    ax.set_title(m, weight='bold')\n",
    "    ax.set_xlim(-xmax, xmax)\n",
    "    ax.set_ylim(-ymax, ymax)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "fig.suptitle('Persona effects by model: ΔEMM (x) vs ΔHedges/100 (y)\\nStars: ΔEMM Holm-significant; Bold outline: ΔHedges Holm-significant', y=0.98, weight='bold')\n",
    "for ax in axes[::2]: ax.set_ylabel('Δ Hedges per 100 words')\n",
    "for ax in axes[2:]:  ax.set_xlabel('Δ EMM (persona − baseline)')\n",
    "\n",
    "plt.tight_layout(rect=[0,0,1,0.94])\n",
    "plt.savefig(os.path.join(\".\", \"figure_deltaEMM_vs_deltaHedges_by_model.png\"), dpi=300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b960f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy import stats\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "# load summary df \n",
    "summary_df = pd.read_csv(os.path.join(output_path, 'rationale_summary_by_model_condition.csv'))\n",
    "# --- short labels for personas ---\n",
    "SHORT = {\n",
    "    'baseline':'BL', 'ignore_world':'IW', 'embrace_world':'EW',\n",
    "    'cultural_white':'WH', 'cultural_black':'BK', 'cultural_asian':'AS',\n",
    "    'cultural_hispanic':'HI', 'cultural_indigenous':'IN',\n",
    "    'cultural_africanamerican':'AA', 'cultural_colorism':'CL',\n",
    "    'cultural_lighter':'LG', 'cultural_darker':'DK'\n",
    "}\n",
    "\n",
    "def annotate_points(ax, d, xcol='delta_emm', ycol='delta_hedges',\n",
    "                    label_col='condition'):\n",
    "    \"\"\"\n",
    "    Label ALL points with persona abbreviations (no significance filtering).\n",
    "    \"\"\"\n",
    "    used = []\n",
    "    for _, row in d.iterrows():\n",
    "        x, y = row[xcol], row[ycol]\n",
    "        # small outward nudge so the label isn’t on top of the dot\n",
    "        dx = 0.02 * (1 if x >= 0 else -1)\n",
    "        dy = 0.02 * (1 if y >= 0 else -1)\n",
    "        tx, ty = x + dx, y + dy\n",
    "\n",
    "        # simple de-overlap: nudge if colliding with previous labels\n",
    "        for _ in range(10):\n",
    "            if any(abs(tx-ux) < 0.03 and abs(ty-uy) < 0.03 for (ux, uy) in used):\n",
    "                tx += 0.02; ty += 0.02\n",
    "            else:\n",
    "                break\n",
    "        used.append((tx, ty))\n",
    "\n",
    "        lab = SHORT.get(str(row[label_col]), str(row[label_col]))\n",
    "        ax.text(tx, ty, lab, ha='left', va='center', fontsize=9, weight='bold',\n",
    "                path_effects=[pe.withStroke(linewidth=3, foreground='white')])\n",
    "        # leader line\n",
    "        ax.plot([x, tx], [y, ty], linewidth=0.6, alpha=0.6)\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Inputs\n",
    "# -----------------------------\n",
    "# `summary_df` must already be in memory\n",
    "emm_path = \"outputs/cross_model_emms.csv\"\n",
    "emm = pd.read_csv(emm_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Standardize condition keys\n",
    "# -----------------------------\n",
    "fix = {'cultural_asain': 'cultural_asian'}\n",
    "for d in (emm, summary_df):\n",
    "    d['condition'] = d['condition'].replace(fix)\n",
    "\n",
    "model_order = ['Claude','GPT','Gemini','Llama']\n",
    "cond_order = ['baseline','cultural_africanamerican','cultural_asian','cultural_black',\n",
    "              'cultural_colorism','cultural_darker','cultural_hispanic','cultural_indigenous',\n",
    "              'cultural_lighter','cultural_white','embrace_world','ignore_world']\n",
    "\n",
    "# -----------------------------\n",
    "# 2) ΔEMM vs baseline within model\n",
    "# -----------------------------\n",
    "base_emm = (emm[emm['condition']=='baseline']\n",
    "            .set_index('model')[['emmean','SE']]\n",
    "            .rename(columns={'emmean':'base_emm','SE':'base_SE'}))\n",
    "\n",
    "emm2 = emm.merge(base_emm, left_on='model', right_index=True, how='left')\n",
    "emm2['delta_emm'] = emm2['emmean'] - emm2['base_emm']\n",
    "emm2['SE_delta']  = np.sqrt(emm2['SE']**2 + emm2['base_SE']**2)  # conservative approx\n",
    "\n",
    "zcrit = stats.norm.ppf(0.975)\n",
    "emm2['delta_emm_lo'] = emm2['delta_emm'] - zcrit*emm2['SE_delta']\n",
    "emm2['delta_emm_hi'] = emm2['delta_emm'] + zcrit*emm2['SE_delta']\n",
    "\n",
    "def holm_stars(group):\n",
    "    g = group[group['condition']!='baseline'].copy()\n",
    "    g['z'] = g['delta_emm'] / g['SE_delta'].replace(0, np.nan)\n",
    "    g['p_raw'] = 2*(1-stats.norm.cdf(np.abs(g['z'])))\n",
    "    if g['p_raw'].notna().any():\n",
    "        mask = g['p_raw'].notna().values\n",
    "        p_adj = np.full(len(g), np.nan)\n",
    "        p_adj[mask] = multipletests(g.loc[mask, 'p_raw'], method='holm')[1]\n",
    "        g['p_adj'] = p_adj\n",
    "    else:\n",
    "        g['p_adj'] = np.nan\n",
    "    def stars(p):\n",
    "        if pd.isna(p): return \"\"\n",
    "        return \"****\" if p < 1e-4 else (\"***\" if p < 1e-3 else (\"**\" if p < 1e-2 else (\"*\" if p < 0.05 else \"\")))\n",
    "    g['emm_stars'] = g['p_adj'].apply(stars)\n",
    "    return g[['model','condition','delta_emm','delta_emm_lo','delta_emm_hi','SE_delta','p_adj','emm_stars']]\n",
    "\n",
    "emm_delta = (emm2.groupby('model', group_keys=False).apply(holm_stars)\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "# add baseline rows (Δ=0)\n",
    "baseline_rows = (emm2[emm2['condition']=='baseline'][['model','condition']].copy())\n",
    "baseline_rows['delta_emm'] = 0.0\n",
    "baseline_rows['delta_emm_lo'] = 0.0\n",
    "baseline_rows['delta_emm_hi'] = 0.0\n",
    "baseline_rows['SE_delta'] = np.nan\n",
    "baseline_rows['p_adj'] = np.nan\n",
    "baseline_rows['emm_stars'] = \"\"\n",
    "emm_delta = pd.concat([emm_delta, baseline_rows], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) ΔHedges/100 vs baseline within model\n",
    "# -----------------------------\n",
    "tbl = summary_df.copy()\n",
    "base_h = (tbl[tbl['condition']=='baseline'][['model','hedges_per_100']]\n",
    "          .rename(columns={'hedges_per_100':'base_h'}))\n",
    "tbl = tbl.merge(base_h, on='model', how='left')\n",
    "tbl['delta_hedges'] = tbl['hedges_per_100'] - tbl['base_h']\n",
    "\n",
    "# (Optional) hedges_sig lookup if you computed Holm tests for hedges:\n",
    "hedges_sig = {}\n",
    "try:\n",
    "    tmp = hedge_results_df.copy()\n",
    "    tmp['condition'] = tmp['condition'].replace(fix)\n",
    "    def stars(p): \n",
    "        if pd.isna(p): return \"\"\n",
    "        return \"****\" if p < 1e-4 else (\"***\" if p < 1e-3 else (\"**\" if p < 1e-2 else (\"*\" if p < 0.05 else \"\")))\n",
    "    tmp['hedge_stars'] = tmp['p_adj'].apply(stars)\n",
    "    hedges_sig = {(r.model, r.condition): r.hedge_stars for r in tmp.itertuples(index=False)}\n",
    "except NameError:\n",
    "    pass  # ok if you haven't run hedging tests\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Merge Δ–Δ\n",
    "# -----------------------------\n",
    "dd = (tbl[['model','condition','delta_hedges']]\n",
    "      .merge(emm_delta, on=['model','condition'], how='inner'))\n",
    "\n",
    "dd['model'] = pd.Categorical(dd['model'], categories=model_order, ordered=True)\n",
    "dd['condition'] = pd.Categorical(dd['condition'], categories=cond_order, ordered=True)\n",
    "dd = dd.sort_values(['model','condition'])\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Plot Δ–Δ (annotate ALL points)\n",
    "# -----------------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 9), sharex=True, sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "xpad = 0.05 * np.nanmax(np.abs(dd['delta_emm'].values)) if np.isfinite(np.nanmax(np.abs(dd['delta_emm'].values))) else 0.2\n",
    "ypad = 0.05 * np.nanmax(np.abs(dd['delta_hedges'].values)) if np.isfinite(np.nanmax(np.abs(dd['delta_hedges'].values))) else 0.2\n",
    "xmax = np.nanmax(np.abs(dd['delta_emm'].values)) + xpad\n",
    "ymax = np.nanmax(np.abs(dd['delta_hedges'].values)) + ypad\n",
    "\n",
    "PT_SIZE = 48  # constant point size\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    ax = axes[i]\n",
    "    d = dd[dd['model']==m].copy()\n",
    "    d = d[d['condition']!='baseline']  # drop baseline point to reduce clutter\n",
    "\n",
    "    # zero lines\n",
    "    ax.axvline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "    ax.axhline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "\n",
    "    # points (constant size)\n",
    "    ax.scatter(d['delta_emm'], d['delta_hedges'], s=PT_SIZE)\n",
    "\n",
    "    # ΔEMM error bars only where significant (declutter)\n",
    "    d_err = d[d['emm_stars'].astype(str).str.len().gt(0)]\n",
    "    ax.errorbar(d_err['delta_emm'], d_err['delta_hedges'],\n",
    "                xerr=[d_err['delta_emm'] - d_err['delta_emm_lo'],\n",
    "                      d_err['delta_emm_hi'] - d_err['delta_emm']],\n",
    "                fmt='none', linewidth=1, alpha=0.9, capsize=2)\n",
    "\n",
    "    # stars for ΔEMM significance (above the point)\n",
    "    yoff = 0.03 * (ymax if np.isfinite(ymax) else 1.0)\n",
    "    for x, y, star in zip(d['delta_emm'], d['delta_hedges'], d['emm_stars']):\n",
    "        if isinstance(star, str) and star:\n",
    "            ax.text(x, y + yoff, star, ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "    # LABEL **ALL** points with persona abbreviations\n",
    "    annotate_points(ax, d, xcol='delta_emm', ycol='delta_hedges', label_col='condition')\n",
    "\n",
    "    ax.set_title(m, weight='bold')\n",
    "    ax.set_xlim(-xmax, xmax)\n",
    "    ax.set_ylim(-ymax, ymax)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "fig.suptitle('LLM skin tone assessments versus hedging terms used in LLM Rationale', y=0.98, weight='bold')\n",
    "for ax in axes[::2]: ax.set_ylabel('Δ Hedges per 100 words')\n",
    "for ax in axes[2:]:  ax.set_xlabel('Difference in skin tone rating (persona - baseline))')\n",
    "\n",
    "plt.tight_layout(rect=[0,0,1,0.94])\n",
    "plt.savefig(os.path.join(\".\", \"figure_deltaEMM_vs_deltaHedges_by_model.png\"), dpi=600, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(\".\", \"figure_deltaEMM_vs_deltaHedges_by_model.pdf\"), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9beb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy import stats\n",
    "import matplotlib.patheffects as pe\n",
    "\n",
    "# -----------------------------\n",
    "# Config: show long names above stars?\n",
    "# -----------------------------\n",
    "SHOW_LONG_ABOVE = True   # set to False to avoid duplicate long names\n",
    "\n",
    "# load summary df \n",
    "summary_df = pd.read_csv(os.path.join(output_path, 'rationale_summary_by_model_condition.csv'))\n",
    "\n",
    "# FULL, human-readable names (used for significant labels)\n",
    "pretty_map = {\n",
    "    'baseline':'Baseline',\n",
    "    'ignore_world':'Ignore world knowledge',\n",
    "    'embrace_world':'Embrace world knowledge',\n",
    "    'cultural_white':'White',\n",
    "    'cultural_black':'Black',\n",
    "    'cultural_asian':'Asian',\n",
    "    'cultural_hispanic':'Hispanic',\n",
    "    'cultural_indigenous':'Indigenous',\n",
    "    'cultural_africanamerican':'African American',\n",
    "    'cultural_colorism':'Colorism',\n",
    "    'cultural_lighter':'Lighter Community',\n",
    "    'cultural_darker':'Darker Community'\n",
    "}\n",
    "\n",
    "# Abbreviations (used for non-significant labels under the dot)\n",
    "SHORT = {\n",
    "    'baseline':'BL', 'ignore_world':'IW', 'embrace_world':'EW',\n",
    "    'cultural_white':'WH', 'cultural_black':'BK', 'cultural_asian':'AS',\n",
    "    'cultural_hispanic':'HI', 'cultural_indigenous':'IN',\n",
    "    'cultural_africanamerican':'AA', 'cultural_colorism':'CL',\n",
    "    'cultural_lighter':'LG', 'cultural_darker':'DK'\n",
    "}\n",
    "\n",
    "# ---------------- helpers ----------------\n",
    "def label_sig_points_above_stars(ax, d, yoff, pad, xcol='delta_emm', ycol='delta_hedges',\n",
    "                                 label_col='condition', star_col='emm_stars'):\n",
    "    \"\"\"Place FULL persona labels directly ABOVE the star for significant points.\"\"\"\n",
    "    used = []\n",
    "    sig = d[d[star_col].astype(str).str.len().gt(0)].copy()\n",
    "    for _, row in sig.iterrows():\n",
    "        x, y = row[xcol], row[ycol]\n",
    "        tx, ty = x, y + yoff + pad  # label directly above the star\n",
    "        # simple de-overlap: nudge upward if colliding\n",
    "        for _ in range(10):\n",
    "            if any(abs(tx-ux) < 0.03 and abs(ty-uy) < 0.03 for (ux, uy) in used):\n",
    "                ty += pad * 0.6\n",
    "            else:\n",
    "                break\n",
    "        used.append((tx, ty))\n",
    "        lab = pretty_map.get(str(row[label_col]), str(row[label_col]))\n",
    "        ax.text(tx, ty, lab, ha='center', va='bottom', fontsize=9, weight='bold',\n",
    "                path_effects=[pe.withStroke(linewidth=3, foreground='white')])\n",
    "\n",
    "def label_below_mixed(ax, d, pad, xcol='delta_emm', ycol='delta_hedges',\n",
    "                      label_col='condition', star_col='emm_stars'):\n",
    "    \"\"\"\n",
    "    Put labels UNDER every dot:\n",
    "      - if significant (has star), use FULL persona name,\n",
    "      - else use abbreviation (SHORT).\n",
    "    \"\"\"\n",
    "    for _, row in d.iterrows():\n",
    "        x, y = row[xcol], row[ycol]\n",
    "        is_sig = isinstance(row.get(star_col, \"\"), str) and len(str(row.get(star_col, \"\"))) > 0\n",
    "        lab = pretty_map.get(str(row[label_col]), str(row[label_col])) if is_sig \\\n",
    "              else SHORT.get(str(row[label_col]), str(row[label_col]))\n",
    "        ty = y - pad\n",
    "        ax.text(x, ty, lab, ha='center', va='top', fontsize=9, weight='bold',\n",
    "                path_effects=[pe.withStroke(linewidth=3, foreground='white')])\n",
    "\n",
    "# -----------------------------\n",
    "# 0) Inputs\n",
    "# -----------------------------\n",
    "emm_path = \"outputs/cross_model_emms.csv\"\n",
    "emm = pd.read_csv(emm_path)\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Standardize condition keys\n",
    "# -----------------------------\n",
    "fix = {'cultural_asain': 'cultural_asian'}\n",
    "for d in (emm, summary_df):\n",
    "    d['condition'] = d['condition'].replace(fix)\n",
    "\n",
    "model_order = ['Claude','GPT','Gemini','Llama']\n",
    "cond_order = ['baseline','cultural_africanamerican','cultural_asian','cultural_black',\n",
    "              'cultural_colorism','cultural_darker','cultural_hispanic','cultural_indigenous',\n",
    "              'cultural_lighter','cultural_white','embrace_world','ignore_world']\n",
    "\n",
    "# -----------------------------\n",
    "# 2) ΔEMM vs baseline within model\n",
    "# -----------------------------\n",
    "base_emm = (emm[emm['condition']=='baseline']\n",
    "            .set_index('model')[['emmean','SE']]\n",
    "            .rename(columns={'emmean':'base_emm','SE':'base_SE'}))\n",
    "\n",
    "emm2 = emm.merge(base_emm, left_on='model', right_index=True, how='left')\n",
    "emm2['delta_emm'] = emm2['emmean'] - emm2['base_emm']\n",
    "emm2['SE_delta']  = np.sqrt(emm2['SE']**2 + emm2['base_SE']**2)  # conservative approx\n",
    "\n",
    "zcrit = stats.norm.ppf(0.975)\n",
    "emm2['delta_emm_lo'] = emm2['delta_emm'] - zcrit*emm2['SE_delta']\n",
    "emm2['delta_emm_hi'] = emm2['delta_emm'] + zcrit*emm2['SE_delta']\n",
    "\n",
    "def holm_stars(group):\n",
    "    g = group[group['condition']!='baseline'].copy()\n",
    "    g['z'] = g['delta_emm'] / g['SE_delta'].replace(0, np.nan)\n",
    "    g['p_raw'] = 2*(1-stats.norm.cdf(np.abs(g['z'])))\n",
    "    if g['p_raw'].notna().any():\n",
    "        mask = g['p_raw'].notna().values\n",
    "        p_adj = np.full(len(g), np.nan)\n",
    "        p_adj[mask] = multipletests(g.loc[mask, 'p_raw'], method='holm')[1]\n",
    "        g['p_adj'] = p_adj\n",
    "    else:\n",
    "        g['p_adj'] = np.nan\n",
    "    def stars(p):\n",
    "        if pd.isna(p): return \"\"\n",
    "        return \"****\" if p < 1e-4 else (\"***\" if p < 1e-3 else (\"**\" if p < 1e-2 else (\"*\" if p < 0.05 else \"\")))\n",
    "    g['emm_stars'] = g['p_adj'].apply(stars)\n",
    "    return g[['model','condition','delta_emm','delta_emm_lo','delta_emm_hi','SE_delta','p_adj','emm_stars']]\n",
    "\n",
    "emm_delta = (emm2.groupby('model', group_keys=False).apply(holm_stars)\n",
    "             .reset_index(drop=True))\n",
    "\n",
    "# add baseline rows (Δ=0)\n",
    "baseline_rows = (emm2[emm2['condition']=='baseline'][['model','condition']].copy())\n",
    "baseline_rows['delta_emm'] = 0.0\n",
    "baseline_rows['delta_emm_lo'] = 0.0\n",
    "baseline_rows['delta_emm_hi'] = 0.0\n",
    "baseline_rows['SE_delta'] = np.nan\n",
    "baseline_rows['p_adj'] = np.nan\n",
    "baseline_rows['emm_stars'] = \"\"\n",
    "emm_delta = pd.concat([emm_delta, baseline_rows], ignore_index=True)\n",
    "\n",
    "# -----------------------------\n",
    "# 3) ΔHedges/100 vs baseline within model\n",
    "# -----------------------------\n",
    "tbl = summary_df.copy()\n",
    "base_h = (tbl[tbl['condition']=='baseline'][['model','hedges_per_100']]\n",
    "          .rename(columns={'hedges_per_100':'base_h'}))\n",
    "tbl = tbl.merge(base_h, on='model', how='left')\n",
    "tbl['delta_hedges'] = tbl['hedges_per_100'] - tbl['base_h']\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Merge Δ–Δ\n",
    "# -----------------------------\n",
    "dd = (tbl[['model','condition','delta_hedges']]\n",
    "      .merge(emm_delta, on=['model','condition'], how='inner'))\n",
    "\n",
    "dd['model'] = pd.Categorical(dd['model'], categories=model_order, ordered=True)\n",
    "dd['condition'] = pd.Categorical(dd['condition'], categories=cond_order, ordered=True)\n",
    "dd = dd.sort_values(['model','condition'])\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Plot Δ–Δ\n",
    "# -----------------------------\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 9), sharex=True, sharey=True)\n",
    "axes = axes.ravel()\n",
    "\n",
    "xpad = 0.05 * np.nanmax(np.abs(dd['delta_emm'].values)) if np.isfinite(np.nanmax(np.abs(dd['delta_emm'].values))) else 0.2\n",
    "ypad = 0.05 * np.nanmax(np.abs(dd['delta_hedges'].values)) if np.isfinite(np.nanmax(np.abs(dd['delta_hedges'].values))) else 0.2\n",
    "xmax = np.nanmax(np.abs(dd['delta_emm'].values)) + xpad\n",
    "ymax = np.nanmax(np.abs(dd['delta_hedges'].values)) + ypad\n",
    "\n",
    "PT_SIZE = 48  # constant point size\n",
    "\n",
    "for i, m in enumerate(model_order):\n",
    "    ax = axes[i]\n",
    "    d = dd[dd['model']==m].copy()\n",
    "    d = d[d['condition']!='baseline']  # drop baseline point to reduce clutter\n",
    "\n",
    "    # zero lines\n",
    "    ax.axvline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "    ax.axhline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "\n",
    "    # points (constant size)\n",
    "    ax.scatter(d['delta_emm'], d['delta_hedges'], s=PT_SIZE)\n",
    "\n",
    "    # ΔEMM error bars only where significant (declutter)\n",
    "    d_err = d[d['emm_stars'].astype(str).str.len().gt(0)]\n",
    "    ax.errorbar(d_err['delta_emm'], d_err['delta_hedges'],\n",
    "                xerr=[d_err['delta_emm'] - d_err['delta_emm_lo'],\n",
    "                      d_err['delta_emm_hi'] - d_err['delta_emm']],\n",
    "                fmt='none', linewidth=1, alpha=0.9, capsize=2)\n",
    "\n",
    "    # stars for ΔEMM significance (just above each significant point)\n",
    "    yoff = 0.03 * (ymax if np.isfinite(ymax) else 1.0)\n",
    "    for x, y, star in zip(d['delta_emm'], d['delta_hedges'], d['emm_stars']):\n",
    "        if isinstance(star, str) and star:\n",
    "            ax.text(x, y + yoff, star, ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "    # NEW: under-dot labels: FULL name if significant, else abbreviation\n",
    "    label_pad_below = 0.05 * (ymax if np.isfinite(ymax) else 1.0)\n",
    "    label_below_mixed(ax, d, pad=label_pad_below,\n",
    "                      xcol='delta_emm', ycol='delta_hedges',\n",
    "                      label_col='condition', star_col='emm_stars')\n",
    "\n",
    "    ax.set_title(m, weight='bold')\n",
    "    ax.set_xlim(-xmax, xmax)\n",
    "    ax.set_ylim(-ymax, ymax)\n",
    "    ax.grid(True, alpha=0.2)\n",
    "\n",
    "fig.suptitle('LLM skin tone assessments versus hedging terms used in LLM Rationale', y=0.98, weight='bold')\n",
    "for ax in axes[::2]: ax.set_ylabel('Δ Hedges per 100 words')\n",
    "for ax in axes[2:]:  ax.set_xlabel('Difference in skin tone rating (persona − baseline)')\n",
    "\n",
    "plt.tight_layout(rect=[0,0,1,0.94])\n",
    "plt.savefig(os.path.join(\".\", \"figure_deltaEMM_vs_deltaHedges_by_model.png\"), dpi=600, bbox_inches='tight')\n",
    "plt.savefig(os.path.join(\".\", \"figure_deltaEMM_vs_deltaHedges_by_model.pdf\"), bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8677da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_delta_emm_by_persona(\n",
    "    emm_delta: pd.DataFrame,\n",
    "    cond_order: list,\n",
    "    model_order: list,\n",
    "    pretty_map: dict,\n",
    "    show_long_labels: bool = True,\n",
    "    save_png: str = None,\n",
    "    save_pdf: str = None\n",
    "):\n",
    "    \"\"\"\n",
    "    Plot ΔEMM (persona - baseline) on Y, persona on X, faceted by model.\n",
    "    Requires columns in emm_delta: ['model','condition','delta_emm','delta_emm_lo','delta_emm_hi','emm_stars'].\n",
    "    \"\"\"\n",
    "    # keep persona rows (drop baseline)\n",
    "    df = emm_delta.copy()\n",
    "    df = df[df['condition'] != 'baseline'].copy()\n",
    "\n",
    "    # order categorical axes\n",
    "    df['model'] = pd.Categorical(df['model'], categories=model_order, ordered=True)\n",
    "    df['condition'] = pd.Categorical(df['condition'], categories=[c for c in cond_order if c != 'baseline'], ordered=True)\n",
    "    df = df.sort_values(['model','condition'])\n",
    "\n",
    "    # build x tick labels\n",
    "    def _lab(c):\n",
    "        return pretty_map.get(str(c), str(c)) if show_long_labels else str(c)\n",
    "    x_labels = [_lab(c) for c in df['condition'].cat.categories]\n",
    "\n",
    "    # figure/grid\n",
    "    n_models = len(model_order)\n",
    "    ncols = 2\n",
    "    nrows = int(np.ceil(n_models / ncols))\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(max(10, 0.9*len(x_labels)*ncols), 4.5*nrows), sharey=True)\n",
    "    if not isinstance(axes, np.ndarray):\n",
    "        axes = np.array([axes])\n",
    "    axes = axes.ravel()\n",
    "\n",
    "    # y-limits padding\n",
    "    ymax = np.nanmax(np.abs(df['delta_emm'].values))\n",
    "    if not np.isfinite(ymax):\n",
    "        ymax = 1.0\n",
    "    pad = 0.1 * ymax\n",
    "    y_lim = (-ymax - pad, ymax + pad)\n",
    "\n",
    "    for i, m in enumerate(model_order):\n",
    "        ax = axes[i]\n",
    "        d = df[df['model'] == m].copy()\n",
    "        # x positions follow the global condition category order\n",
    "        xs = np.arange(len(df['condition'].cat.categories))\n",
    "        # align data to that order\n",
    "        d = d.set_index('condition').reindex(df['condition'].cat.categories).reset_index()\n",
    "\n",
    "        # zero line\n",
    "        ax.axhline(0, linestyle='--', linewidth=0.8, alpha=0.6)\n",
    "\n",
    "        # points\n",
    "        ax.scatter(xs, d['delta_emm'], s=40, zorder=3)\n",
    "\n",
    "        # error bars (use precomputed CI)\n",
    "        xerr_lo = d['delta_emm'] - d['delta_emm_lo']\n",
    "        xerr_hi = d['delta_emm_hi'] - d['delta_emm']\n",
    "        # guard NaNs\n",
    "        eb_mask = d[['delta_emm_lo','delta_emm_hi']].notna().all(axis=1)\n",
    "        ax.vlines(xs[eb_mask], d.loc[eb_mask, 'delta_emm_lo'], d.loc[eb_mask, 'delta_emm_hi'], linewidth=2, alpha=0.9)\n",
    "\n",
    "        # stars above points\n",
    "        yoff = 0.03 * (y_lim[1] - y_lim[0])\n",
    "        for x, y, star in zip(xs, d['delta_emm'], d['emm_stars'].fillna('')):\n",
    "            if isinstance(star, str) and len(star) > 0:\n",
    "                ax.text(x, y + yoff, star, ha='center', va='bottom', fontsize=11, weight='bold')\n",
    "\n",
    "        ax.set_title(m, weight='bold')\n",
    "        ax.set_xticks(xs)\n",
    "        ax.set_xticklabels(x_labels, rotation=35, ha='right')\n",
    "        ax.set_ylim(*y_lim)\n",
    "        ax.grid(True, alpha=0.2)\n",
    "\n",
    "    # hide any unused axes\n",
    "    for j in range(i+1, len(axes)):\n",
    "        axes[j].axis('off')\n",
    "\n",
    "    fig.suptitle('Difference in skin tone rating (persona − baseline) by persona', y=0.98, weight='bold')\n",
    "    for r in range(nrows):\n",
    "        axes[r*ncols].set_ylabel('Δ Skin tone rating (persona − baseline)')\n",
    "    # x-label on bottom row\n",
    "    for c in range((nrows-1)*ncols, nrows*ncols):\n",
    "        if c < len(axes) and axes[c].has_data():\n",
    "            axes[c].set_xlabel('Persona')\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.94])\n",
    "\n",
    "    if save_png:\n",
    "        plt.savefig(save_png, dpi=600, bbox_inches='tight')\n",
    "    if save_pdf:\n",
    "        plt.savefig(save_pdf, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_delta_emm_by_persona(\n",
    "    emm_delta=emm_delta,\n",
    "    cond_order=cond_order,\n",
    "    model_order=model_order,\n",
    "    pretty_map=pretty_map,\n",
    "    show_long_labels=True,\n",
    "    save_png=os.path.join(\".\", \"figure_deltaEMM_by_persona_by_model.png\"),\n",
    "    save_pdf=os.path.join(\".\", \"figure_deltaEMM_by_persona_by_model.pdf\"),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff26f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_delta_emm_combined(\n",
    "    emm_delta: pd.DataFrame,\n",
    "    cond_order: list,\n",
    "    model_order: list,\n",
    "    pretty_map: dict,\n",
    "    show_long_labels: bool = True,\n",
    "    save_png: str = None,\n",
    "    save_pdf: str = None,\n",
    "    max_offset: float = 0.18\n",
    "):\n",
    "    \"\"\"\n",
    "    Combined plot of ΔEMM (persona - baseline) on Y, persona on X, with all models on a single axes.\n",
    "    Expects columns in emm_delta: ['model','condition','delta_emm','delta_emm_lo','delta_emm_hi','emm_stars'].\n",
    "    Parameters:\n",
    "        - emm_delta: DataFrame\n",
    "        - cond_order: list of conditions (including 'baseline')\n",
    "        - model_order: list of models (order for legend / offsets)\n",
    "        - pretty_map: mapping for condition display labels\n",
    "        - show_long_labels: whether to use pretty_map for x labels\n",
    "        - save_png/save_pdf: optional paths\n",
    "        - max_offset: horizontal spread for model points around a persona tick\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.lines as mlines\n",
    "    from itertools import cycle\n",
    "\n",
    "    # copy & drop baseline rows (we plot delta = persona - baseline)\n",
    "    df = emm_delta.copy()\n",
    "    df = df[df['condition'] != 'baseline'].copy()\n",
    "\n",
    "    # categorical ordering for conditions and models\n",
    "    df['model'] = pd.Categorical(df['model'], categories=model_order, ordered=True)\n",
    "    conds_no_base = [c for c in cond_order if c != 'baseline']\n",
    "    df['condition'] = pd.Categorical(df['condition'], categories=conds_no_base, ordered=True)\n",
    "    df = df.sort_values(['condition','model'])  # sort by persona then model for stable plotting\n",
    "\n",
    "    # x labels\n",
    "    def _lab(c):\n",
    "        return pretty_map.get(str(c), str(c)) if show_long_labels else str(c)\n",
    "    x_labels = [_lab(c) for c in df['condition'].cat.categories]\n",
    "    personas = df['condition'].cat.categories.tolist()\n",
    "\n",
    "    # color mapping (same families as prior)\n",
    "    model_colors = {\n",
    "        'GPT': '#2ecc71',    # Green\n",
    "        'Claude': '#e74c3c', # Red\n",
    "        'Llama': '#3498db',  # Blue\n",
    "        'Gemini': '#f1c40f', # Yellow\n",
    "    }\n",
    "    default_palette = ['#8e44ad', '#16a085', '#d35400', '#2c3e50', '#7f8c8d']\n",
    "    default_cycle = cycle(default_palette)\n",
    "\n",
    "    models_present = [m for m in model_order if m in df['model'].cat.categories or m in df['model'].unique()]\n",
    "    if len(models_present) == 0:\n",
    "        raise ValueError(\"No models found in dataframe according to model_order.\")\n",
    "\n",
    "    # assign color per model (try to map family by name)\n",
    "    model_to_color = {}\n",
    "    for m in models_present:\n",
    "        family = next((family for family in model_colors if family.lower() in str(m).lower()), None)\n",
    "        model_to_color[m] = model_colors.get(family, next(default_cycle))\n",
    "\n",
    "    # x base positions\n",
    "    x_base = np.arange(len(personas))\n",
    "\n",
    "    # prepare offsets for models so multiple models at same persona spread slightly\n",
    "    n_models = len(models_present)\n",
    "    if n_models > 1:\n",
    "        offsets = np.linspace(-max_offset, max_offset, n_models)\n",
    "    else:\n",
    "        offsets = np.array([0.0])\n",
    "\n",
    "    # compute symmetric y-limits (based on delta_emm values)\n",
    "    ymax = np.nanmax(np.abs(df['delta_emm'].values))\n",
    "    if not np.isfinite(ymax):\n",
    "        ymax = 1.0\n",
    "    pad = 0.12 * ymax\n",
    "    y_lim = (-ymax - pad, ymax + pad)\n",
    "\n",
    "    # create plot\n",
    "    fig, ax = plt.subplots(figsize=(max(10, 0.9*len(x_labels)), 6))\n",
    "\n",
    "    # zero line\n",
    "    ax.axhline(0, linestyle='--', linewidth=0.9, alpha=0.6)\n",
    "\n",
    "    # for legend handles (dots only)\n",
    "    legend_handles = []\n",
    "\n",
    "    # Plot models one-by-one using offsets\n",
    "    for i, model in enumerate(models_present):\n",
    "        offset = offsets[i]\n",
    "        color = model_to_color[model]\n",
    "        # subset\n",
    "        mdf = df[df['model'] == model].set_index('condition').reindex(personas).reset_index()\n",
    "        means = mdf['delta_emm'].values.astype(float)\n",
    "        lo = mdf['delta_emm_lo'].values.astype(float)\n",
    "        hi = mdf['delta_emm_hi'].values.astype(float)\n",
    "\n",
    "        # x positions aligned to persona ticks with offset\n",
    "        xs = x_base + offset\n",
    "\n",
    "        # plot points (skip NaNs)\n",
    "        valid = ~np.isnan(means)\n",
    "        if valid.any():\n",
    "            ax.scatter(xs[valid], means[valid], s=50, color=color, edgecolor='k', linewidth=0.4, zorder=4)\n",
    "\n",
    "            # vertical error bars (precomputed lower/upper bounds)\n",
    "            # ensure we only draw for rows with finite lo/hi\n",
    "            eb_mask = (~np.isnan(lo)) & (~np.isnan(hi))\n",
    "            if eb_mask.any():\n",
    "                ax.vlines(xs[eb_mask], lo[eb_mask], hi[eb_mask], linewidth=2, alpha=0.9, color=color, zorder=3)\n",
    "\n",
    "            # significance stars above points\n",
    "            yoff = 0.03 * (y_lim[1] - y_lim[0])\n",
    "            for x_val, y_val, star in zip(xs[valid], means[valid], mdf.loc[valid, 'emm_stars'].fillna('')):\n",
    "                if isinstance(star, str) and len(star) > 0:\n",
    "                    ax.text(x_val, y_val + yoff, star, ha='center', va='bottom', fontsize=11, weight='bold', zorder=6)\n",
    "\n",
    "        # add a legend handle (dot only)\n",
    "        legend_handles.append(mlines.Line2D([], [], color=color, marker='o', linestyle='None', markersize=7, label=model))\n",
    "\n",
    "    # finalize axes\n",
    "    ax.set_xticks(x_base)\n",
    "    ax.set_xticklabels(x_labels, rotation=35, ha='right', fontsize=10)\n",
    "    ax.set_ylim(*y_lim)\n",
    "    ax.set_ylabel('Δ Skin tone rating (persona − baseline)')\n",
    "    ax.set_xlabel('Persona')\n",
    "    ax.set_title('Difference in skin tone rating (persona − baseline) — all models', weight='bold')\n",
    "\n",
    "    ax.grid(axis='y', linestyle='--', alpha=0.25)\n",
    "\n",
    "    # legend (dots only)\n",
    "    ax.legend(handles=legend_handles, title='Model', bbox_to_anchor=(1.02, 1), loc='upper left', borderaxespad=0.)\n",
    "\n",
    "    plt.tight_layout(rect=[0, 0, 0.88, 0.95])\n",
    "\n",
    "    # save if requested\n",
    "    if save_png:\n",
    "        plt.savefig(save_png, dpi=600, bbox_inches='tight')\n",
    "    if save_pdf:\n",
    "        plt.savefig(save_pdf, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "plot_delta_emm_combined(\n",
    "    emm_delta=emm_delta,\n",
    "    cond_order=cond_order,\n",
    "    model_order=model_order,\n",
    "    pretty_map=pretty_map,\n",
    "    show_long_labels=True,\n",
    "    save_png=os.path.join(\".\", \"figure_deltaEMM_by_persona_combined.png\"),\n",
    "    save_pdf=os.path.join(\".\", \"figure_deltaEMM_by_persona_combined.pdf\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d97c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute within-model shift range (max change across personas within each model)\n",
    "within_model = (\n",
    "    emm_delta[emm_delta[\"condition\"] != \"baseline\"]\n",
    "    .groupby(\"model\")[\"delta_emm\"]\n",
    "    .agg(lambda x: x.max() - x.min())\n",
    ")\n",
    "max_within_model_shift = within_model.max().round(2)\n",
    "\n",
    "# Compute between-model shift range for the same persona\n",
    "# (how much the same persona's delta differs across models)\n",
    "between_model = (\n",
    "    emm_delta[emm_delta[\"condition\"] != \"baseline\"]\n",
    "    .groupby(\"condition\")[\"delta_emm\"]\n",
    "    .agg(lambda x: x.max() - x.min())\n",
    ")\n",
    "max_between_model_shift = between_model.max().round(2)\n",
    "\n",
    "print(f\"Within a model, changes reached {max_within_model_shift} points; \"\n",
    "      f\"between models, ratings for the same persona differed by up to {max_between_model_shift} points.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
